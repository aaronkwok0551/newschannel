#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HK News Monitor - Uses MiniMax AI to determine relevant news
"""

import requests
import feedparser
import datetime
import pytz
import os
import json
import time

# Hong Kong Timezone
HK_TZ = pytz.timezone('Asia/Hong_Kong')

# RSS Sources to monitor
RSS_SOURCES = {
    # Government RSS
    'ÊîøÂ∫úÊñ∞ËÅû': 'https://www.info.gov.hk/gia/rss/general_zh.xml',
    
    # News Sources with AI filtering
    'HK01': 'https://news.hk01.com/rss/focus/2135',
    'on.cc': 'https://news.on.cc/hk/import/rdf/news.rdf',
    'nowÊñ∞ËÅû': 'https://news.now.com/home/rss.xml',
    'RTHK': 'https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml',
    'ÊòüÂ≥∂': 'https://www.stheadline.com/rss',
    'ÊòéÂ†±': 'https://news.mingpao.com/rss/ins/all.xml',
}

def send_telegram(message):
    """Send message to Telegram"""
    bot_token = os.environ.get('TELEGRAM_BOT_TOKEN')
    chat_id = os.environ.get('TELEGRAM_CHAT_ID')
    
    if not bot_token or not chat_id:
        print("‚ö†Ô∏è Telegram credentials not set")
        return False
    
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    data = {
        'chat_id': chat_id,
        'text': message,
        'parse_mode': 'Markdown',
        'disable_web_page_preview': True
    }
    
    try:
        response = requests.post(url, json=data, timeout=10)
        if response.ok:
            print("‚úÖ Telegram notification sent")
            return True
        else:
            print(f"‚ùå Telegram failed: {response.text}")
    except Exception as e:
        print(f"‚ùå Telegram error: {e}")
    return False

def check_with_minimax(title, source):
    """Use MiniMax AI to check if news is relevant"""
    api_key = os.environ.get('MINIMAX_API_KEY', '')
    
    # Regions to EXCLUDE
    exclude_regions = ['Êó•Êú¨', 'Âè∞ÁÅ£', 'Áè†Êµ∑', 'Êæ≥ÈñÄ', 'Êæ≥Ê¥≤', '‰∏≠Âúã', 'ÂÖßÂú∞', 'Â§ßÈô∏', 'Ê∑±Âú≥', 'Âª£Â∑û', 'Âåó‰∫¨', '‰∏äÊµ∑', 'Ê≥∞Âúã', 'È¶¨‰æÜË•ø‰∫û', 'Êñ∞Âä†Âù°', 'ÈüìÂúã', 'Ëã±Âúã', 'ÁæéÂúã', 'Âä†ÊãøÂ§ß']
    
    # Very strict fallback keywords (must be HK-related)
    keywords = ['ÊØíÂìÅ', 'Êµ∑Èóú', '‰øùÂÆâÂ±Ä', 'ÈÑßÁÇ≥Âº∑', 'Á∑ùÊØí', 'Â§™Á©∫Ê≤π', '‰æùË®óÂí™ÈÖØ', 'Á¶ÅÊØí', 'Ëµ∞ÁßÅ', 'Ê™¢Áç≤', 'Êà™Áç≤', 'È¶ôÊ∏Ø', 'Ê∏ØÂ≥∂', '‰πùÈæç', 'Êñ∞Áïå']
    
    # First check: exclude non-HK regions
    for region in exclude_regions:
        if region in title:
            print(f"   üö´ Excluded (non-HK region: {region})")
            return False
    
    if not api_key:
        print(f"   ‚ö†Ô∏è MINIMAX_API_KEY not set!")
        result = any(kw in title for kw in keywords) and 'È¶ôÊ∏Ø' in title
        print(f"   üîç Keyword check (no AI): {result}")
        return result
    
    try:
        url = "https://api.minimax.chat/v1/text/chatcompletion_v2"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "MiniMax-M2.1",
            "messages": [
                {
                    "role": "system",
                    "content": "‰Ω†‰øÇ‰∏ÄÂÄãÂö¥Ê†ºÊó¢È¶ôÊ∏ØÊñ∞ËÅûÁ∑®ËºØ„ÄÇÈÅéÊøæÊ®ôÊ∫ñÔºö\n1. Âè™Êé•Âèó„ÄåÈ¶ôÊ∏Ø„ÄçÊú¨Âú∞Êó¢ÊØíÂìÅ„ÄÅÊµ∑Èóú„ÄÅ‰øùÂÆâÂ±ÄÊñ∞ËÅû\n2. ‰∏ÄÊó¶Ê®ôÈ°åÂá∫Áèæ„ÄåÊó•Êú¨„ÄÅÂè∞ÁÅ£„ÄÅÁè†Êµ∑„ÄÅÊæ≥ÈñÄ„ÄÅÊæ≥Ê¥≤„ÄÅ‰∏≠Âúã„ÄÅÂÖßÂú∞„ÄÅÂ§ßÈô∏„ÄÅÊ∑±Âú≥„ÄÅÂª£Â∑û„ÄçÂë¢Âï≤Âú∞ÂçÄÔºåÂÖ®ÈÉ®ÈÉΩ‰øÇNO\n3. È¶ôÊ∏ØÂú∞Áî¢„ÄÅÂ®õÊ®Ç„ÄÅÊîøÊ≤ªÂÖ∂‰ªñÂú∞ÊñπÊñ∞ËÅûÈÉΩ‰øÇNO\n4. È¶ôÊ∏ØÊµ∑Èóú/Ë≠¶ÂØü/Á∑ùÊØíÊó¢Êñ∞ËÅûÂÖàYES"
                },
                {
                    "role": "user",
                    "content": f"""Âö¥Ê†ºÂà§Êñ∑Âë¢Ê¢ùÊ®ôÈ°å‰øÇÂí™„ÄåÈ¶ôÊ∏ØÊú¨Âú∞Êó¢ÊØíÂìÅ/Êµ∑Èóú/‰øùÂÆâÂ±Ä„ÄçÊñ∞ËÅûÔºö

Ê®ôÈ°å: {title}
‰æÜÊ∫ê: {source}

‚ùå Â¶ÇÊûúÊ®ôÈ°åÊúâ‰ª•‰∏ãÊÉÖÊ≥ÅÔºåÂøÖÈ†àÁ≠îNOÔºö
- ÊèêÂà∞Êó•Êú¨„ÄÅÂè∞ÁÅ£„ÄÅÁè†Êµ∑„ÄÅÊæ≥ÈñÄ„ÄÅÊæ≥Ê¥≤„ÄÅ‰∏≠Âúã„ÄÅÂÖßÂú∞„ÄÅÂ§ßÈô∏Á≠âÈùûÈ¶ôÊ∏ØÂú∞ÂçÄ
- Á¥îÁ≤πÈ¶ôÊ∏ØÂú∞Áî¢/Ê®ìÁõ§
- È¶ôÊ∏ØÂ®õÊ®ÇÂúà/TVB
- ‰∏ÄËà¨È¶ôÊ∏ØÁ§æÊúÉÊñ∞ËÅûÔºàÂîîÈóúÊØíÂìÅ/Êµ∑Èóú/‰øùÂÆâÂ±ÄÔºâ

‚úÖ Âè™ÊúâÂë¢Âï≤ÂÖàYESÔºö
- È¶ôÊ∏ØÊú¨Âú∞ÊØíÂìÅÁõ∏ÈóúÊñ∞ËÅû
- È¶ôÊ∏ØÊµ∑ÈóúÁ∑ùÊØí/Ëµ∞ÁßÅÊñ∞ËÅû
- È¶ôÊ∏Ø‰øùÂÆâÂ±Ä/Á¶ÅÊØíËôï/Ë≠¶ÂØüÁ∑ùÊØíÊñ∞ËÅû

Ë´ãÂè™ÂõûÁ≠î„ÄåYES„ÄçÊàñ„ÄåNO„Äç"""
                }
            ],
            "max_tokens": 10,
            "temperature": 0.1
        }
        
        print(f"   üîÑ Calling MiniMax API...")
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        print(f"   üì° API response status: {response.status_code}")
        print(f"   üìù Raw response (first 300 chars): {response.text[:300]}")
        
        if response.status_code == 200:
            result = response.json()
            
            # Try different response formats
            answer = None
            
            # Format 1: OpenAI-style (choices)
            if 'choices' in result and len(result['choices']) > 0:
                answer = result['choices'][0]['message']['content'].strip().upper()
            
            # Format 2: MiniMax direct
            elif 'text' in result:
                answer = result['text'].strip().upper()
            
            # Format 3: Look for answer in base_resp
            elif 'base_resp' in result:
                text_content = result.get('base_resp', {}).get('text_content', '')
                if text_content:
                    answer = text_content.strip().upper()
            
            if answer:
                print(f"   üìù AI answer: {answer}")
                return answer == 'YES'
            else:
                print(f"   ‚ö†Ô∏è No answer found in response")
                return any(kw in title for kw in keywords) and 'È¶ôÊ∏Ø' in title
        elif response.status_code == 401 or response.status_code == 403:
            print(f"   ‚ùå API auth failed (status {response.status_code})")
            return any(kw in title for kw in keywords) and 'È¶ôÊ∏Ø' in title
        else:
            print(f"   ‚ö†Ô∏è API error: {response.status_code}")
            return any(kw in title for kw in keywords) and 'È¶ôÊ∏Ø' in title
        
    except Exception as e:
        print(f"   ‚ùå AI check failed: {e}")
        return any(kw in title for kw in keywords) and 'È¶ôÊ∏Ø' in title

    return any(kw in title for kw in keywords)

def parse_rss_source(name, url):
    """Parse RSS/JSON source and return matching articles"""
    articles = []
    now = datetime.datetime.now(HK_TZ)
    
    try:
        if 'news.google.com' in url:
            feed = feedparser.parse(url)
            for entry in feed.entries[:30]:
                if check_with_minimax(entry.title, name):
                    time_struct = getattr(entry, 'published_parsed', None)
                    if time_struct:
                        dt_obj = datetime.datetime.fromtimestamp(
                            time.mktime(time_struct), HK_TZ
                        )
                        if (now - dt_obj).total_seconds() < 86400:
                            articles.append({
                                'source': name,
                                'title': entry.title.rsplit(' - ', 1)[0],
                                'link': entry.link,
                                
                                'datetime': dt_obj
                            })
        elif 'wenweipo.com' in url:
            response = requests.get(url, timeout=15)
            data = response.json()
            for item in data.get('data', [])[:30]:
                title = item.get('title', '')
                if check_with_minimax(title, 'ÊñáÂåØÂ†±'):
                    pub_date = item.get('publishTime') or item.get('updated')
                    if pub_date:
                        try:
                            dt_obj = datetime.datetime.strptime(
                                pub_date, "%Y-%m-%dT%H:%M:%S.%f%z"
                            )
                            if (now - dt_obj.astimezone(HK_TZ)).total_seconds() < 86400:
                                articles.append({
                                    'source': 'ÊñáÂåØÂ†±',
                                    'title': title,
                                    'link': item.get('url', ''),
                                    
                                    'datetime': dt_obj
                                })
                        except:
                            pass
        else:
            response = requests.get(url, timeout=15)
            feed = feedparser.parse(response.content)
            for entry in feed.entries[:30]:
                if check_with_minimax(entry.title, name):
                    time_struct = getattr(entry, 'updated_parsed', None) or getattr(entry, 'published_parsed', None)
                    if time_struct:
                        dt_obj = datetime.datetime.fromtimestamp(
                            time.mktime(time_struct), HK_TZ
                        )
                        if (now - dt_obj).total_seconds() < 86400:
                            articles.append({
                                'source': name,
                                'title': entry.title.rsplit(' - ', 1)[0],
                                'link': entry.link,
                                
                                'datetime': dt_obj
                            })
    except Exception as e:
        print(f"‚ùå Error fetching {name}: {e}")
    
    return articles

def main():
    print(f"\nüïê [{datetime.datetime.now(HK_TZ).strftime('%Y-%m-%d %H:%M:%S')}] Starting AI news monitor...")
    print(f"üì° Monitoring {len(RSS_SOURCES)} sources")
    
    # Check API key
    api_key = os.environ.get('MINIMAX_API_KEY', '')
    if api_key:
        print(f"ü§ñ MiniMax API key: {api_key[:10]}...")
    else:
        print("‚ö†Ô∏è MINIMAX_API_KEY not set, using keyword fallback")
    
    print()
    
    all_articles = []
    
    for name, url in RSS_SOURCES.items():
        print(f"üì• Fetching {name}...")
        articles = parse_rss_source(name, url)
        all_articles.extend(articles)
        print(f"   ‚Üí Found {len(articles)} AI-matched articles")
    
    # Sort by time
    all_articles.sort(key=lambda x: x['datetime'], reverse=True)
    
    # Remove duplicates
    seen = set()
    unique_articles = []
    for article in all_articles:
        title_key = article['title'][:30]
        if title_key not in seen:
            seen.add(title_key)
            unique_articles.append(article)
    
    # Group by source
    articles_by_source = {}
    for article in unique_articles:
        source = article['source']
        if source not in articles_by_source:
            articles_by_source[source] = []
        articles_by_source[source].append(article)
    
    print(f"\nüìä Articles by source: {dict((k, len(v)) for k, v in articles_by_source.items())}")
    
    # Save to file in new format
    with open('new_articles.txt', 'w', encoding='utf-8') as f:
        f.write("üì∞ Á∂úÂêàÂ™íÈ´îÂø´Ë®ä (ÂΩôÊï¥)\n\n")
        for source, articles in articles_by_source.items():
            # Emoji mapping
            emoji_map = {
                'ÊîøÂ∫úÊñ∞ËÅû': 'üì∞',
                'HK01': 'üì∞',
                'on.cc': 'üì∞',
                'nowÊñ∞ËÅû': 'üì∞',
                'Á¶ÅÊØí/Êµ∑Èóú': 'üì∞',
                'RTHK': 'üì∞',
                'ÊòüÂ≥∂': 'üêØ',
                'ÊòéÂ†±': 'üìù',
                'ÊñáÂåØÂ†±': 'üì∞',
            }
            emoji = emoji_map.get(source, 'üì∞')
            f.write(f"{emoji} {source}\n")
            for article in articles[:8]:  # Max 8 per source
                title = article['title'].replace('\n', ' ').strip()
                f.write(f"‚Ä¢ [{title}]({article['link']})\n")
            f.write("\n")
    
    # Send notification
    if unique_articles:
        message = "üì∞ Á∂úÂêàÂ™íÈ´îÂø´Ë®ä (ÂΩôÊï¥)\n\n"
        
        for source, articles in articles_by_source.items():
            emoji_map = {
                'ÊîøÂ∫úÊñ∞ËÅû': 'üì∞',
                'HK01': 'üì∞',
                'on.cc': 'üì∞',
                'nowÊñ∞ËÅû': 'üì∞',
                'Á¶ÅÊØí/Êµ∑Èóú': 'üì∞',
                'RTHK': 'üì∞',
                'ÊòüÂ≥∂': 'üêØ',
                'ÊòéÂ†±': 'üìù',
                'ÊñáÂåØÂ†±': 'üì∞',
            }
            emoji = emoji_map.get(source, 'üì∞')
            message += f"{emoji} {source}\n"
            for article in articles[:5]:  # Max 5 per source
                title = article['title'].replace('\n', ' ').strip()
                message += f"‚Ä¢ [{title}]({article['link']})\n"
            message += "\n"
        
        message += f"üîó https://github.com/aaronkwok0551/newschannel"
        
        # Only send if 8am-10pm HKT
        now_hkt = datetime.datetime.now(HK_TZ)
        if 8 <= now_hkt.hour <= 22:
            send_telegram(message)
            print(f"\n‚úÖ Notification sent for {len(unique_articles)} articles")
        else:
            print(f"\n‚è∞ Outside monitoring hours, notification skipped")
    else:
        print("\nüì≠ No matching articles found")
    
    print(f"\n‚úÖ Monitor complete at {datetime.datetime.now(HK_TZ).strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main()
