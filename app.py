# app.py
import os
import re
import html
import time
from datetime import datetime, date
from urllib.parse import urlparse

import requests
import feedparser
import streamlit as st

try:
    import pytz
    HK_TZ = pytz.timezone("Asia/Hong_Kong")
except Exception:
    HK_TZ = None

# ---------------------------
# Config
# ---------------------------
DEFAULT_RSSHUB_BASE = os.getenv("RSSHUB_BASE", "").rstrip("/")
# ä¾‹ï¼šRSSHUB_BASE=https://rsshub.app æˆ–ä½ è‡ªå·±éƒ¨ç½²å˜… https://xxxx.railway.app
# è‹¥ç•™ç©ºï¼ŒRSSHub ä¾†æºæœƒé¡¯ç¤ºã€Œæœªè¨­å®šã€

NOW_CATEGORY_DEFAULT = "119"  # æ¸¯èï¼ˆä½ æä¾›å˜…ä¾‹å­ï¼‰

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; NewsHub/1.0; +https://example.com)"
}

TIMEOUT = 12

# ---------------------------
# Helpers
# ---------------------------
def hk_now() -> datetime:
    if HK_TZ:
        return datetime.now(HK_TZ)
    return datetime.now()

def hk_today() -> date:
    return hk_now().date()

def safe_text(s: str) -> str:
    s = s or ""
    s = re.sub(r"\s+", " ", s).strip()
    return html.escape(s)

def normalize_url(u: str) -> str:
    if not u:
        return ""
    u = u.strip()
    return u

def is_today(dt: datetime) -> bool:
    if not dt:
        return False
    return dt.date() == hk_today()

def parse_feed_datetime(entry) -> datetime | None:
    # feedparser: entry.published_parsed / updated_parsed (time.struct_time)
    for key in ("published_parsed", "updated_parsed"):
        t = getattr(entry, key, None)
        if t:
            try:
                # treat as local time; if HK_TZ exists, localize
                d = datetime(*t[:6])
                if HK_TZ:
                    return HK_TZ.localize(d)
                return d
            except Exception:
                pass
    return None

def fetch_rss(url: str, limit: int = 10, today_only: bool = False):
    items = []
    err = None
    if not url:
        return items, "URL is empty"

    try:
        # feedparser can read via URL directly, but using requests gives better control
        r = requests.get(url, headers=HEADERS, timeout=TIMEOUT)
        r.raise_for_status()
        feed = feedparser.parse(r.content)

        for e in feed.entries[: max(50, limit * 3)]:
            title = getattr(e, "title", "") or ""
            link = getattr(e, "link", "") or ""
            dt = parse_feed_datetime(e)

            if today_only and dt and not is_today(dt):
                continue

            items.append(
                {
                    "title": title.strip(),
                    "link": normalize_url(link),
                    "time": dt.strftime("%H:%M") if dt else "",
                    "dt": dt,
                }
            )
            if len(items) >= limit:
                break
    except Exception as ex:
        err = f"RSS fetch failed: {ex}"

    return items, err

def fetch_now_news(category: str = NOW_CATEGORY_DEFAULT, page_no: int = 1, page_size: int = 20, limit: int = 10, today_only: bool = False):
    """
    Now æ–°èï¼šä½¿ç”¨ä½ æä¾›å˜… JSON API æ ¼å¼ï¼ˆnewsapi1.now.com / getNewsListv2ï¼‰
    """
    items = []
    err = None

    # ä½ æˆªåœ–é¡¯ç¤º path: /pccw-news-api/api/getNewsListv2?category=119&pageNo=1...
    url = "https://newsapi1.now.com/pccw-news-api/api/getNewsListv2"
    params = {
        "category": str(category),
        "pageNo": str(page_no),
        "pageSize": str(page_size),
    }

    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=TIMEOUT)
        r.raise_for_status()
        data = r.json()

        # ä½ æä¾›ä¾‹å­ä¿‚ list[dict]ï¼Œä½†æœ‰æ©ŸæœƒåŒ…ä¸€å±¤ dict
        if isinstance(data, dict):
            # å¸¸è¦‹ï¼š{"newsList":[...]} æˆ– {"data":[...]}
            for k in ("newsList", "data", "result", "items"):
                if k in data and isinstance(data[k], list):
                    data = data[k]
                    break

        if not isinstance(data, list):
            return [], "Now API returned unexpected JSON structure"

        for it in data:
            title = (it.get("title") or it.get("storyTitle") or "").strip()
            news_id = (it.get("newsId") or "").strip()

            # Now æœ‰æ™‚ webUrl ç‚º nullï¼Œä½ ä¾‹å­è¦‹åˆ°å…§æ–‡æœ‰ linkï¼ˆplayer?newsId=xxxxxï¼‰
            link = it.get("webUrl")
            if not link and news_id:
                # ç”¨ä½ ä¾‹å­ä¸­å‡ºç¾éå˜…è·¯å¾‘å½¢å¼ï¼ˆæœ€ç©©ç”¨ newsId çµ„ï¼‰
                # local / international å…¶å¯¦å¯ç”± categoryName/æ¬„ç›®æ±ºå®šï¼Œä½†å…ˆç”¨ home/local/player
                link = f"https://news.now.com/home/local/player?newsId={news_id}"

            publish_ms = it.get("publishDate")
            dt = None
            if isinstance(publish_ms, (int, float)):
                try:
                    dt_utc = datetime.utcfromtimestamp(publish_ms / 1000.0)
                    if HK_TZ:
                        dt = pytz.utc.localize(dt_utc).astimezone(HK_TZ)
                    else:
                        dt = dt_utc
                except Exception:
                    dt = None

            if today_only and dt and not is_today(dt):
                continue

            if title:
                items.append(
                    {
                        "title": title,
                        "link": normalize_url(link),
                        "time": dt.strftime("%H:%M") if dt else "",
                        "dt": dt,
                    }
                )
            if len(items) >= limit:
                break

    except Exception as ex:
        err = f"Now API fetch failed: {ex}"

    return items, err

def build_rsshub_url(rsshub_base: str, path: str) -> str:
    rsshub_base = (rsshub_base or "").rstrip("/")
    if not rsshub_base:
        return ""
    if not path.startswith("/"):
        path = "/" + path
    return f"{rsshub_base}{path}"

def dedup_items(items: list[dict]) -> list[dict]:
    seen = set()
    out = []
    for it in items:
        key = (it.get("link") or it.get("title") or "").strip()
        if not key:
            continue
        if key in seen:
            continue
        seen.add(key)
        out.append(it)
    return out

def render_cards(source_name: str, items: list[dict], color: str = "#777", err: str | None = None):
    today_str = hk_today().strftime("%Y-%m-%d")
    st.markdown(
        f"""
        <div style="display:flex;align-items:flex-end;justify-content:space-between;margin:4px 0 8px 0;">
          <div style="font-weight:700;font-size:16px;">{safe_text(source_name)}</div>
          <div style="color:#666;font-size:12px;">ä»Šæ—¥ {today_str}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    if err:
        st.markdown(f"<div style='color:#b00020;font-size:12px;margin-bottom:6px;'>{safe_text(err)}</div>", unsafe_allow_html=True)

    if not items:
        st.markdown("<div style='color:#666;font-size:13px;padding:10px;border:1px dashed #ddd;border-radius:10px;'>ä»Šæ—¥æš«ç„¡æ›´æ–°ï¼ˆæˆ–ä¾†æºæš«æ™‚æŠ“å–ä¸åˆ°ï¼‰</div>", unsafe_allow_html=True)
        return

    # å¡ç‰‡
    cards_html = []
    for it in items:
        title = safe_text(it.get("title", ""))
        link = it.get("link", "")
        t = safe_text(it.get("time", ""))
        left_bar = f"background:{color};"

        if link:
            title_html = f"<a href='{html.escape(link)}' target='_blank' rel='noopener noreferrer' style='text-decoration:none;color:#111;'>{title}</a>"
        else:
            title_html = f"<span style='color:#111;'>{title}</span>"

        cards_html.append(
            f"""
            <div style="border:1px solid #eee;border-radius:12px;padding:10px 12px;margin:8px 0;display:flex;gap:10px;">
              <div style="width:6px;border-radius:8px;{left_bar}"></div>
              <div style="flex:1;">
                <div style="font-size:14px;line-height:1.35;font-weight:600;">{title_html}</div>
                <div style="margin-top:6px;color:#666;font-size:12px;">ğŸ•’ {t if t else "--:--"}</div>
              </div>
            </div>
            """
        )

    st.markdown("".join(cards_html), unsafe_allow_html=True)

# ---------------------------
# Streamlit UI
# ---------------------------
st.set_page_config(page_title="é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ", layout="wide")

st.title("é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ")

# refresh control
col_a, col_b, col_c = st.columns([1.2, 1.2, 2.6])
with col_a:
    auto_refresh = st.toggle("æ¯åˆ†é˜è‡ªå‹•æ›´æ–°", value=True)
with col_b:
    today_only = st.toggle("åªé¡¯ç¤ºä»Šæ—¥", value=True)
with col_c:
    rsshub_base = st.text_input("RSSHUB_BASEï¼ˆç•™ç©ºå‰‡åœç”¨ RSSHub ä¾†æºï¼‰", value=DEFAULT_RSSHUB_BASE, placeholder="ä¾‹å¦‚ï¼šhttps://rsshub.app æˆ–ä½ çš„è‡ªå»º RSSHub")

if auto_refresh:
    # Streamlit 1.33+ æœ‰ st.autorefreshï¼›èˆŠç‰ˆæœ¬ç”¨ st.experimental_rerun + sleep æœƒé˜»å¡
    try:
        st.autorefresh(interval=60_000, key="autorefresh")
    except Exception:
        pass

st.caption(f"æœ€å¾Œæ›´æ–°ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰ï¼š{hk_now().strftime('%Y-%m-%d %H:%M:%S')}")

# ---------------------------
# Sources
# ---------------------------
# é¡è‰²åªä¿‚ UI å·¦é‚Šè‰²æ¢
SOURCES = [
    # æ”¿åºœæ–°èï¼ˆå®˜æ–¹ RSSï¼Œå””ç¶“ RSSHubï¼‰
    {
        "name": "æ”¿åºœæ–°èï¼ˆä¸­æ–‡ï¼‰",
        "type": "rss",
        "url": "https://www.info.gov.hk/gia/rss/general_zh.xml",
        "color": "#E74C3C",
        "limit": 10,
    },
    {
        "name": "æ”¿åºœæ–°èï¼ˆè‹±æ–‡ï¼‰",
        "type": "rss",
        "url": "https://www.info.gov.hk/gia/rss/general.xml",
        "color": "#C0392B",
        "limit": 10,
    },

    # RTHKï¼ˆå®˜æ–¹ RSSï¼‰
    {
        "name": "RTHKï¼ˆæœ¬åœ°ï¼‰",
        "type": "rss",
        "url": "https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml",
        "color": "#FF9800",
        "limit": 10,
    },

    # Nowï¼ˆå””ç”¨ RSSHubï¼Œç›´æ¥ JSON APIï¼‰
    {
        "name": "Now æ–°èï¼ˆæ¸¯èï¼‰",
        "type": "now_api",
        "category": NOW_CATEGORY_DEFAULT,
        "color": "#3B82F6",
        "limit": 10,
    },

    # RSSHub sourcesï¼ˆéœ€è¦ RSSHUB_BASEï¼‰
    {
        "name": "HK01ï¼ˆæœ€æ–°ï¼‰",
        "type": "rsshub",
        "path": "/hk01/latest",
        "color": "#10B981",
        "limit": 10,
    },
    {
        "name": "on.cc æ±ç¶²ï¼ˆæ–°èï¼‰",
        "type": "rsshub",
        "path": "/oncc/zh-hant/news",
        "color": "#7C3AED",
        "limit": 10,
    },
    {
        "name": "TVB æ–°èï¼ˆç¹ä¸­ï¼‰",
        "type": "rsshub",
        "path": "/tvb/news/tc",
        "color": "#111827",
        "limit": 10,
    },
    {
        "name": "ä¿¡å ±å³æ™‚ï¼ˆhkejï¼‰",
        "type": "rsshub",
        "path": "/hkej/index",
        "color": "#0EA5E9",
        "limit": 10,
    },
    {
        "name": "æ˜Ÿå³¶å³æ™‚",
        "type": "rsshub",
        "path": "/stheadline/std/realtime",
        "color": "#F97316",
        "limit": 10,
    },
    {
        "name": "i-CABLE æœ‰ç·š",
        "type": "rsshub",
        "path": "/icable/all",
        "color": "#EF4444",
        "limit": 10,
    },
    {
        "name": "Nowï¼ˆRSSHub ç‰ˆï¼Œå¯èƒ½æœƒå£ï¼‰",
        "type": "rsshub",
        "path": "/now/news",
        "color": "#2563EB",
        "limit": 10,
    },

    # æ˜å ±ï¼šä½ è©±ã€Œå®˜æ–¹ RSSã€â€”æˆ‘å””å¼·è¡ŒçŒœ URLï¼Œç•™ä¸€å€‹ä½ç½®ä¿¾ä½ å¡«
    {
        "name": "æ˜å ±ï¼ˆå®˜æ–¹ RSSï¼šè«‹å¡« URLï¼‰",
        "type": "rss",
        "url": "",  # <- ä½ æµåˆ°å®˜æ–¹ RSS URL å¾Œå¡«å‘¢åº¦
        "color": "#6B7280",
        "limit": 10,
    },
]

# ---------------------------
# Fetch & Render
# ---------------------------
# é é¢æ’ç‰ˆï¼šå…©è¡Œ gridï¼ˆä½ å¯è‡ªè¡Œæ”¹ columns æ•¸é‡ï¼‰
cols = st.columns(4)

for idx, src in enumerate(SOURCES):
    c = cols[idx % 4]
    with c:
        items = []
        err = None

        if src["type"] == "rss":
            items, err = fetch_rss(src.get("url", ""), limit=src.get("limit", 10), today_only=today_only)

            # å¦‚æœä¿‚ã€Œæ˜å ±ã€è€Œ url ä¿‚ç©ºï¼Œä¿¾æ›´æ¸…æ™°è¨Šæ¯
            if not src.get("url"):
                err = "æœªè¨­å®š RSS URLï¼ˆè«‹åœ¨ app.py è£œä¸Šå®˜æ–¹ RSS é€£çµï¼‰"
                items = []

        elif src["type"] == "rsshub":
            url = build_rsshub_url(rsshub_base, src.get("path", ""))
            if not rsshub_base:
                err = "æœªè¨­å®š RSSHUB_BASEï¼ˆå·²åœç”¨ RSSHub ä¾†æºï¼‰"
                items = []
            else:
                items, err = fetch_rss(url, limit=src.get("limit", 10), today_only=today_only)

        elif src["type"] == "now_api":
            items, err = fetch_now_news(
                category=src.get("category", NOW_CATEGORY_DEFAULT),
                page_no=1,
                page_size=20,
                limit=src.get("limit", 10),
                today_only=today_only,
            )

        # å»é‡ï¼ˆé¿å…åŒä¸€æ¢é‡è¦†ï¼‰
        items = dedup_items(items)

        # é¡¯ç¤º
        render_cards(src["name"], items, color=src.get("color", "#777"), err=err)
