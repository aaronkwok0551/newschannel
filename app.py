# app.py
# -*- coding: utf-8 -*-

import datetime
import html
import sys
import time
from dataclasses import dataclass
from typing import List, Optional, Tuple, Dict

import feedparser
import pytz
import requests
import streamlit as st
from bs4 import BeautifulSoup
from dateutil import parser as dtparser
from streamlit_autorefresh import st_autorefresh

# =====================
# åŸºæœ¬è¨­å®š
# =====================
try:
    sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass

HK_TZ = pytz.timezone("Asia/Hong_Kong")
NEW_HIGHLIGHT_MINUTES = 20

st.set_page_config(page_title="é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ", layout="wide", page_icon="ğŸ—ï¸")

# =====================
# CSSï¼ˆä¸æ”¹æ’ç‰ˆï¼ŒåªåŠ  new é«˜äº®æ¨£å¼ï¼‰
# =====================
st.markdown(
    """
<style>
body { font-family: "Microsoft JhengHei","PingFang TC",sans-serif; }

.section-title{
  font-size:1.1rem;font-weight:800;margin:2px 0 8px 0;
}

.card{
  background:#fff;border:1px solid #e5e7eb;border-radius:12px;
  padding:12px;height:520px;display:flex;flex-direction:column;
}

.items{ overflow-y:auto; padding-right:6px; flex:1; }

.item{
  background:#fff;border-left:4px solid #3b82f6;border-radius:8px;
  padding:8px 10px;margin:8px 0;
}

.item a{
  text-decoration:none;color:#111827;font-weight:600;line-height:1.35;
}
.item a:hover{ color:#ef4444; }

.item-meta{
  font-size:0.78rem;color:#6b7280;font-family:monospace;margin-top:2px;
}

.empty{ color:#9ca3af;text-align:center;margin-top:20px; }

/* NEW: æ–°è 20 åˆ†é˜ç´…è‰²æç¤ºï¼ˆä¸æ”¹ layoutï¼‰ */
.item.new{
  border-left-color:#ef4444 !important;
  background: rgba(239,68,68,0.06);
}
.item.new a{
  color:#b91c1c;
}
</style>
""",
    unsafe_allow_html=True,
)

# =====================
# Model
# =====================
@dataclass
class Article:
    title: str
    link: str
    time_str: str
    color: str
    dt: Optional[datetime.datetime] = None  # ç”¨æ–¼æ’åºï¼ˆæœ€æ–°åœ¨ä¸Šï¼‰

# =====================
# Helpers
# =====================
def now_hk() -> datetime.datetime:
    return datetime.datetime.now(HK_TZ)

def clean_text(raw: str) -> str:
    raw = html.unescape(raw or "")
    soup = BeautifulSoup(raw, "html.parser")
    return soup.get_text(" ", strip=True)

def parse_time_from_feed_entry(entry) -> Optional[datetime.datetime]:
    # feedparser æ¨™æº–æ¬„ä½
    if getattr(entry, "published_parsed", None):
        return datetime.datetime(*entry.published_parsed[:6], tzinfo=pytz.utc).astimezone(HK_TZ)
    if getattr(entry, "updated_parsed", None):
        return datetime.datetime(*entry.updated_parsed[:6], tzinfo=pytz.utc).astimezone(HK_TZ)

    # æ–‡å­—æ¬„ä½å˜—è©¦ parse
    for key in ("published", "updated", "pubDate"):
        val = getattr(entry, key, None)
        if val:
            try:
                dt = dtparser.parse(str(val))
                if dt.tzinfo is None:
                    dt = HK_TZ.localize(dt)
                return dt.astimezone(HK_TZ)
            except Exception:
                pass
    return None

def _safe_get_json(url: str, params: Optional[dict] = None, timeout: int = 12):
    r = requests.get(url, params=params, timeout=timeout, headers={"User-Agent": "Mozilla/5.0"})
    r.raise_for_status()
    return r.json()

def _epoch_ms_to_dt(ms: int) -> datetime.datetime:
    # Now API publishDate = epoch ms
    return datetime.datetime.fromtimestamp(ms / 1000.0, tz=HK_TZ)

def sort_articles_latest_first(items: List[Article]) -> List[Article]:
    # dt æœ‰ -> ç”±æ–°åˆ°èˆŠï¼›dt ç„¡ -> æ”¾æœ€å¾Œ
    def key(a: Article):
        return a.dt or datetime.datetime(1970, 1, 1, tzinfo=HK_TZ)
    return sorted(items, key=key, reverse=True)

# =====================
# Fetchers
# =====================
@st.cache_data(ttl=60)
def fetch_rss_today(url: str, color: str, limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    RSSï¼ˆæ”¿åºœ/RTHK/æ˜å ±ç­‰ï¼‰ï¼š
    - åªé¡¯ç¤ºä»Šæ—¥ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰
    - æœ‰æ™‚é–“ï¼šHH:MM
    - å†‡æ™‚é–“ä½†å¯åˆ¤æ–·æ—¥æœŸï¼šé¡¯ç¤ºã€Œä»Šæ—¥ã€ï¼ˆä¸¦ç”¨ dt=ä»Šæ—¥ 00:00 æ’åºåˆ°è¼ƒå¾Œï¼‰
    - å®Œå…¨å†‡æ—¥æœŸï¼šfallback å–æœ€æ–°10ï¼ˆtime_str=ä»Šæ—¥ï¼Œdt=Noneï¼‰
    """
    feed = feedparser.parse(url)
    today = now_hk().date()

    out_today: List[Article] = []
    out_undated: List[Article] = []

    for e in feed.entries or []:
        title = clean_text(getattr(e, "title", ""))
        link = getattr(e, "link", "")
        if not title or not link:
            continue

        dt = parse_time_from_feed_entry(e)
        if dt:
            if dt.date() == today:
                out_today.append(Article(title=title, link=link, time_str=dt.strftime("%H:%M"), color=color, dt=dt))
        else:
            # å†‡æ™‚é–“å†‡æ—¥æœŸï¼šå…ˆæ”¾å…¥ undatedï¼Œå¯èƒ½æœƒ fallback ç”¨
            out_undated.append(Article(title=title, link=link, time_str="ä»Šæ—¥", color=color, dt=None))

    if out_today:
        out_today = sort_articles_latest_first(out_today)[:limit]
        return out_today, None

    if out_undated:
        return out_undated[:limit], "æ­¤ä¾†æºæœªæä¾›å¯è§£ææ™‚é–“ï¼æ—¥æœŸï¼Œå·²æ”¹ç‚ºé¡¯ç¤ºæœ€æ–° 10 æ¢ï¼ˆæ™‚é–“é¡¯ç¤ºã€ä»Šæ—¥ã€ï¼‰"

    return [], "RSS ç„¡å…§å®¹æˆ–æš«æ™‚è®€å–ä¸åˆ°"

@st.cache_data(ttl=60)
def fetch_rss_latest(url: str, color: str, limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    RSSï¼ˆä¸åšä»Šæ—¥éæ¿¾ï¼‰ï¼šå–æœ€æ–° 10ï¼Œä¸¦æŒ‰ dt æ’åºï¼ˆå¦‚æœæœ‰ï¼‰
    """
    feed = feedparser.parse(url)
    out: List[Article] = []
    for e in feed.entries or []:
        title = clean_text(getattr(e, "title", ""))
        link = getattr(e, "link", "")
        if not title or not link:
            continue
        dt = parse_time_from_feed_entry(e)
        time_str = dt.strftime("%H:%M") if dt else "å³æ™‚"
        out.append(Article(title=title, link=link, time_str=time_str, color=color, dt=dt))
        if len(out) >= limit:
            break

    if out:
        out = sort_articles_latest_first(out)
        return out, None
    return [], "RSS ç„¡å…§å®¹æˆ–æš«æ™‚è®€å–ä¸åˆ°"

@st.cache_data(ttl=60)
def fetch_now_local_today(color: str, limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    Now æ–°èï¼ˆæœ¬åœ°ï¼‰ï¼š
    - category=119
    - åªé¡¯ç¤ºä»Šæ—¥ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰
    - publishDate ç‚º epoch ms
    """
    today = now_hk().date()
    NOW_API = "https://newsapi1.now.com/pccw-news-api/api/getNewsListv2"

    out_today: List[Article] = []
    out_latest: List[Article] = []

    try:
        data = _safe_get_json(NOW_API, {"category": 119, "pageNo": 1}, timeout=12)

        # Now æœ‰æ™‚ç›´æ¥å› listï¼Œæœ‰æ™‚å› dict åŒ… list
        candidates = None
        if isinstance(data, list):
            candidates = data
        elif isinstance(data, dict):
            for k in ("data", "list", "news", "items", "result"):
                v = data.get(k)
                if isinstance(v, list):
                    candidates = v
                    break
            if candidates is None:
                for v in data.values():
                    if isinstance(v, dict):
                        for kk in ("data", "list", "news", "items", "result"):
                            vv = v.get(kk)
                            if isinstance(vv, list):
                                candidates = vv
                                break
                    if candidates is not None:
                        break

        if not candidates:
            return [], "Now API å›å‚³çµæ§‹å·²è®Šï¼ˆæ‰¾ä¸åˆ°æ–°èåˆ—è¡¨ï¼‰"

        for it in candidates:
            if not isinstance(it, dict):
                continue

            title = clean_text(str(it.get("newsTitle") or it.get("title") or it.get("headline") or ""))
            link = str(it.get("webUrl") or it.get("shareUrl") or it.get("url") or it.get("link") or "")
            if link.startswith("/"):
                link = "https://news.now.com" + link

            dt = None
            time_str = "ä»Šæ—¥"
            raw = it.get("publishDate") or it.get("publishTime") or it.get("publishedAt") or it.get("date")
            if raw is not None:
                try:
                    if isinstance(raw, (int, float)) or (isinstance(raw, str) and raw.isdigit()):
                        dt = _epoch_ms_to_dt(int(raw))
                    else:
                        dt = dtparser.parse(str(raw))
                        if dt.tzinfo is None:
                            dt = HK_TZ.localize(dt)
                        dt = dt.astimezone(HK_TZ)
                    time_str = dt.strftime("%H:%M")
                except Exception:
                    dt = None
                    time_str = "ä»Šæ—¥"

            if title and link:
                art = Article(title=title, link=link, time_str=time_str, color=color, dt=dt)
                out_latest.append(art)
                if dt and dt.date() == today:
                    out_today.append(art)

            if len(out_latest) >= limit:
                break

        if out_today:
            out_today = sort_articles_latest_first(out_today)[:limit]
            return out_today, None

        if out_latest:
            out_latest = sort_articles_latest_first(out_latest)[:limit]
            return out_latest, "æœªèƒ½ç¯©å‡ºã€ä»Šæ—¥ã€æ–°èï¼Œå·²æ”¹ç‚ºé¡¯ç¤ºæœ€æ–° 10 æ¢ï¼ˆè«‹ç¢ºèª publishDate æ™‚å€ï¼æ ¼å¼ï¼‰"

        return [], "Now API æœ‰å›å‚³ä½†æœªèƒ½è§£æåˆ°æœ‰æ•ˆæ–°èé …ç›®"

    except Exception as e:
        return [], f"Now API è®€å–å¤±æ•—ï¼š{type(e).__name__}: {e}"

# =====================
# NEW: æ–°èã€Œç¬¬ä¸€æ¬¡è¦‹åˆ°ã€è¿½è¹¤ + 20 åˆ†é˜ç´…è‰²
# =====================
def _init_seen_state():
    if "seen_map" not in st.session_state:
        # link -> first_seen_epoch (seconds)
        st.session_state["seen_map"] = {}

def mark_and_check_is_new(link: str) -> bool:
    """
    å›å‚³ï¼šæ­¤æ–°èæ˜¯å¦å±¬æ–¼ã€Œæ–°å‡ºç¾å¾Œ 20 åˆ†é˜å…§ã€
    """
    _init_seen_state()
    seen_map: Dict[str, float] = st.session_state["seen_map"]
    now_ts = time.time()

    if link not in seen_map:
        seen_map[link] = now_ts
        st.session_state["seen_map"] = seen_map
        return True

    first = seen_map[link]
    return (now_ts - first) <= (NEW_HIGHLIGHT_MINUTES * 60)

# =====================
# Renderï¼ˆä¸€æ¬¡æ€§è¼¸å‡ºï¼Œé¿å… DOM æ–·è£‚ï¼›ä¸¦åŠ å…¥ new classï¼‰
# =====================
def build_card_html(title: str, articles: List[Article], note: Optional[str] = None) -> str:
    if not articles:
        items_html = "<div class='empty'>ä»Šæ—¥æš«ç„¡æ–°è</div>"
    else:
        parts = []
        for a in articles:
            is_new = mark_and_check_is_new(a.link)
            new_cls = " new" if is_new else ""
            parts.append(
                f"""
                <div class="item{new_cls}" style="border-left-color:{a.color}">
                  <a href="{a.link}" target="_blank" rel="noopener noreferrer">{a.title}</a>
                  <div class="item-meta">ğŸ• {a.time_str}</div>
                </div>
                """
            )
        items_html = "".join(parts)

    note_html = f"<div class='item-meta' style='margin:0 0 6px 0;'>âš ï¸ {html.escape(note)}</div>" if note else ""

    return f"""
    <div class="section-title">{title}</div>
    <div class="card">
      {note_html}
      <div class="items">
        {items_html}
      </div>
    </div>
    """

# =====================
# URLsï¼ˆä½ æ—¢ rsshub domainï¼‰
# =====================
RSSHUB = "https://rsshub-production-9dfc.up.railway.app"

GOV_ZH = "https://www.info.gov.hk/gia/rss/general_zh.xml"
GOV_EN = "https://www.info.gov.hk/gia/rss/general_en.xml"
RTHK = "https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml"

# ä½ åˆ—å‡ºæ—¢ RSSHub routes
HK01 = f"{RSSHUB}/hk01/latest"
ONCC = f"{RSSHUB}/oncc/zh-hant/news"
TVB = f"{RSSHUB}/tvb/news/tc"
HKEJ = f"{RSSHUB}/hkej/index"
STHEADLINE = f"{RSSHUB}/stheadline/std/realtime"
ICABLE = f"{RSSHUB}/icable/all"

# =====================
# UI
# =====================
st.title("ğŸ—ï¸ é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ")
st.caption(f"æœ€å¾Œæ›´æ–°ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰ï¼š{now_hk().strftime('%Y-%m-%d %H:%M:%S')}ï½œæ–°å‡ºç¾æ–°èç´…è‰²ç¶­æŒ {NEW_HIGHLIGHT_MINUTES} åˆ†é˜")

if st.toggle("æ¯åˆ†é˜è‡ªå‹•æ›´æ–°", value=True):
    st_autorefresh(interval=60_000, key="auto")

# ä½ è©±ã€Œç¾åœ¨å¾ˆå¥½ï¼Œä¸è¦ä¿®æ”¹æ’ç‰ˆäº†ã€ï¼šä»¥ä¸‹åªç¶­æŒæ©«å‘ä¸¦åˆ— columnï¼ˆä½ å¯è‡ªè¡ŒæŒ‰ä½ åŸæœ¬æƒ³è¦å˜…æ•¸é‡èª¿æ•´ï¼‰
# å¦‚ä½ åŸæœ¬ä¿‚ã€Œæ¯è¡Œ 4 å€‹ã€ï¼Œå°± keep 4ï¼›å¦‚æœä½ ä¿‚ã€Œæ¯è¡Œ 5/6 å€‹ã€ï¼Œä½ ç…§åŠ å¤šå¹¾å€‹ column groupã€‚
row1 = st.columns(4)
row2 = st.columns(4)
row3 = st.columns(4)

# ---------- Row 1 ----------
with row1[0]:
    items, note = fetch_rss_today(GOV_ZH, "#E74C3C")
    st.markdown(build_card_html("æ”¿åºœæ–°èï¼ˆä¸­æ–‡ï¼‰", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row1[1]:
    items, note = fetch_rss_today(GOV_EN, "#C0392B")
    st.markdown(build_card_html("æ”¿åºœæ–°èï¼ˆè‹±æ–‡ï¼‰", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row1[2]:
    items, note = fetch_rss_today(RTHK, "#FF9800")
    st.markdown(build_card_html("RTHK", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row1[3]:
    items, note = fetch_now_local_today("#10B981")
    st.markdown(build_card_html("Nowï¼ˆæ¸¯è 119ï¼‰", sort_articles_latest_first(items), note), unsafe_allow_html=True)

# ---------- Row 2 ----------
with row2[0]:
    items, note = fetch_rss_latest(HK01, "#3B82F6")
    st.markdown(build_card_html("HK01", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row2[1]:
    items, note = fetch_rss_latest(ONCC, "#111827")
    st.markdown(build_card_html("on.cc æ±ç¶²", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row2[2]:
    items, note = fetch_rss_latest(TVB, "#1D4ED8")
    st.markdown(build_card_html("TVB æ–°è", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row2[3]:
    items, note = fetch_rss_latest(HKEJ, "#7C3AED")
    st.markdown(build_card_html("ä¿¡å ±å³æ™‚", sort_articles_latest_first(items), note), unsafe_allow_html=True)

# ---------- Row 3 ----------
with row3[0]:
    items, note = fetch_rss_latest(STHEADLINE, "#F59E0B")
    st.markdown(build_card_html("æ˜Ÿå³¶å³æ™‚", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row3[1]:
    items, note = fetch_rss_latest(ICABLE, "#EF4444")
    st.markdown(build_card_html("i-CABLE æœ‰ç·š", sort_articles_latest_first(items), note), unsafe_allow_html=True)

with row3[2]:
    st.markdown(build_card_html("ï¼ˆé ç•™ï¼‰", [], None), unsafe_allow_html=True)

with row3[3]:
    st.markdown(build_card_html("ï¼ˆé ç•™ï¼‰", [], None), unsafe_allow_html=True)
