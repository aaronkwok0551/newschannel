# -*- coding: utf-8 -*-
import streamlit as st
import requests
import feedparser
import datetime
import pytz
import urllib.parse
import time
from bs4 import BeautifulSoup
import sys
from streamlit_autorefresh import st_autorefresh

# è¨­å®šé è¨­ç·¨ç¢¼
try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass

# --- 1. é é¢èˆ‡è‡ªå®šç¾©æ¨£å¼ (å«é–ƒçˆç‰¹æ•ˆ) ---
st.set_page_config(
    page_title="Tommy Sir å¾Œæ´æœƒä¹‹æ–°èç›£å¯Ÿç³»çµ±",
    page_icon="ğŸ“°",
    layout="wide"
)

# è‡ªå‹•åˆ·æ–° (æ¯ 60 ç§’)
st_autorefresh(interval=60 * 1000, limit=None, key="news_autoupdate")

st.markdown("""
<style>
    /* é–ƒçˆç‰¹æ•ˆ */
    @keyframes blinker {
        50% { opacity: 0; }
    }
    .new-badge {
        color: #ff4b4b;
        font-weight: bold;
        animation: blinker 1s linear infinite;
        margin-right: 5px;
    }
    .read-text {
        color: #a0a0a0 !important;
    }
    .stCheckbox { margin-bottom: 0px; }
    .news-source-header { 
        font-size: 1.2em; 
        font-weight: bold; 
        color: #1e293b; 
        margin-top: 15px; 
        margin-bottom: 10px;
        padding-bottom: 5px;
        border-bottom: 2px solid #ddd;
    }
    a { text-decoration: none; color: #2980b9; }
    div[data-testid="column"] { display: flex; align-items: start; }
    .generated-box {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 10px;
        border: 1px solid #dcdfe6;
    }
</style>
""", unsafe_allow_html=True)

# è¨­å®šæ™‚å€
HK_TZ = pytz.timezone('Asia/Hong_Kong')
UTC_TZ = pytz.timezone('UTC')

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
}

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

def fetch_full_article(url):
    """ æŠ“å–å®Œæ•´çš„æ­£æ–‡å…§å®¹ """
    try:
        r = requests.get(url, headers=HEADERS, timeout=5)
        r.encoding = 'utf-8'
        soup = BeautifulSoup(r.text, 'html.parser')
        paragraphs = soup.find_all('p')
        if not paragraphs:
            return "ç„¡æ³•æŠ“å–å…¨æ–‡ï¼Œè«‹é»æ“Šé€£çµæŸ¥çœ‹åŸæ–‡ã€‚"
        full_text = "\n".join([p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > 10])
        return full_text if len(full_text) > 20 else "å…§å®¹æŠ“å–å—é™ï¼Œè«‹é»æ“Šé€£çµã€‚"
    except Exception as e:
        return f"å…¨æ–‡æŠ“å–å¤±æ•—: {str(e)}"

def resolve_google_url(url):
    if "news.google.com" not in url:
        return url
    try:
        r = requests.head(url, headers=HEADERS, allow_redirects=True, timeout=5)
        return r.url
    except:
        return url

def is_new_news(published_time_str):
    """ åˆ¤æ–·æ˜¯å¦ç‚º 15 åˆ†é˜å…§çš„æ–°è """
    try:
        pub_time = datetime.datetime.strptime(published_time_str, '%Y-%m-%d %H:%M')
        pub_time = HK_TZ.localize(pub_time)
        now = datetime.datetime.now(HK_TZ)
        diff = (now - pub_time).total_seconds() / 60
        return diff <= 15
    except:
        return False

@st.cache_data(ttl=60)
def fetch_news_data(func, *args):
    return func(*args)

# æŠ“å–é‚è¼¯ (å°è£åŸæœ¬çš„ fetch å‡½æ•¸)
def fetch_google_rss(site_domain, site_name, color):
    query = urllib.parse.quote(f"site:{site_domain}")
    rss_url = f"https://news.google.com/rss/search?q={query}+when:1d&hl=zh-HK&gl=HK&ceid=HK:zh-Hant"
    feed = feedparser.parse(rss_url)
    news = []
    for entry in feed.entries[:8]:
        title = entry.title.rsplit(" - ", 1)[0] if " - " in entry.title else entry.title
        dt_str = ""
        if hasattr(entry, 'published_parsed'):
            dt_obj = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed), UTC_TZ).astimezone(HK_TZ)
            dt_str = dt_obj.strftime('%Y-%m-%d %H:%M')
        news.append({'source': site_name, 'title': title, 'link': entry.link, 'time': dt_str, 'color': color})
    return news

def fetch_hk01():
    try:
        r = requests.get("https://web-data.api.hk01.com/v2/feed/category/0", headers=HEADERS, timeout=5)
        items = r.json().get('items', [])[:8]
        news = []
        for item in items:
            raw = item.get('data', {})
            dt_str = datetime.datetime.fromtimestamp(raw.get('publishTime'), HK_TZ).strftime('%Y-%m-%d %H:%M')
            news.append({'source': "HK01", 'title': raw.get('title'), 'link': raw.get('publishUrl'), 'time': dt_str, 'color': "#184587"})
        return news
    except: return []

# --- 3. åˆå§‹åŒ–ç‹€æ…‹ ---

if 'selected_links' not in st.session_state:
    st.session_state.selected_links = set()
if 'generated_text' not in st.session_state:
    st.session_state.generated_text = ""

# --- 4. UI ä»‹é¢ ---

st.title("Tommy Sir å¾Œæ´æœƒä¹‹æ–°èç›£å¯Ÿç³»çµ±")
st.caption(f"ç›®å‰æ™‚é–“: {datetime.datetime.now(HK_TZ).strftime('%Y-%m-%d %H:%M:%S')}")

# ç”Ÿæˆå…§å®¹é¡¯ç¤ºå€åŸŸ
if st.session_state.generated_text:
    with st.expander("ğŸ“„ å·²ç”Ÿæˆçš„ TXT å…§å®¹é è¦½ (å¯ç›´æ¥è¤‡è£½)", expanded=True):
        st.text_area("å…§å®¹:", value=st.session_state.generated_text, height=300)
        if st.button("é—œé–‰é è¦½"):
            st.session_state.generated_text = ""
            st.rerun()

# å´é‚Šæ¬„æ§åˆ¶
with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±æ§åˆ¶")
    if st.button("ğŸ”„ ç«‹å³åˆ·æ–°æ‰€æœ‰æ–°è"):
        st.cache_data.clear()
        st.rerun()
    
    st.divider()
    st.write(f"ç›®å‰å·²é¸æ“‡: **{len(st.session_state.selected_links)}** ç¯‡")
    
    if st.button("ğŸ“„ ç”Ÿæˆ TXT å…§å®¹", type="primary"):
        if not st.session_state.selected_links:
            st.warning("è«‹å…ˆå‹¾é¸æ–°è")
        else:
            with st.spinner("æ­£åœ¨æ•´ç†å…¨æ–‡ä¸­..."):
                final_txt = ""
                # é€™è£¡éœ€è¦å¾å¿«å–ä¸­æ¯”å°è³‡æ–™
                # ç°¡å–®èµ·è¦‹ï¼Œæˆ‘å€‘åœ¨ä¸»è¿´åœˆä¸­æ”¶é›†æ‰€æœ‰ç•¶å‰æŠ“å–çš„æ–°è
                for item in st.session_state.all_current_news:
                    if item['link'] in st.session_state.selected_links:
                        real_url = resolve_google_url(item['link'])
                        content = fetch_full_article(real_url)
                        final_txt += f"{item['source']}ï¼š{item['title']}\n"
                        final_txt += f"[{item['time']}]\n\n"
                        final_txt += f"{content}\n\n"
                        final_txt += f"{real_url}\n\n"
                        final_txt += "Ends\n\n"
                st.session_state.generated_text = final_txt
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰é¸æ“‡"):
        st.session_state.selected_links.clear()
        st.session_state.generated_text = ""
        st.rerun()

# --- 5. æ–°èæŠ“å–èˆ‡é¡¯ç¤º ---

sources = [
    ("HK01", fetch_hk01, []),
    ("ç„¡ç·šæ–°è", fetch_google_rss, ["news.tvb.com/tc/local", "ç„¡ç·šæ–°è", "#27ae60"]),
    ("Now æ–°è", fetch_google_rss, ["news.now.com/home/local", "Now æ–°è", "#E65100"]),
]

cols = st.columns(3)
st.session_state.all_current_news = [] # ç”¨æ–¼ç”Ÿæˆæ™‚æ¯”å°

for i, (name, func, args) in enumerate(sources):
    with cols[i % 3]:
        news_items = fetch_news_data(func, *args)
        st.session_state.all_current_news.extend(news_items)
        
        st.markdown(f"<div class='news-source-header'>{name}</div>", unsafe_allow_html=True)
        
        if not news_items:
            st.write("æš«ç„¡æ›´æ–°")
        else:
            for item in news_items:
                link = item['link']
                is_new = is_new_news(item['time'])
                is_selected = link in st.session_state.selected_links
                
                # UI æ’ç‰ˆ
                c1, c2 = st.columns([0.15, 0.85])
                with c1:
                    # å‹¾é¸æ¡†
                    if st.checkbox("", key=f"chk_{link}", value=is_selected):
                        st.session_state.selected_links.add(link)
                    else:
                        st.session_state.selected_links.discard(link)
                
                with c2:
                    new_tag = '<span class="new-badge">NEW!</span>' if is_new else ''
                    text_class = "read-text" if is_selected else ""
                    st.markdown(f"""
                        {new_tag}
                        <a href="{link}" target="_blank" class="{text_class}">
                            <b>{item['title']}</b>
                        </a><br>
                        <small style="color:gray;">{item['time']}</small>
                    """, unsafe_allow_html=True)
