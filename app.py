# app.py
# -*- coding: utf-8 -*-

import datetime
import html
import sys
from dataclasses import dataclass
from typing import List, Optional, Tuple, Dict, Any

import feedparser
import pytz
import requests
import streamlit as st
from bs4 import BeautifulSoup
from dateutil import parser as dtparser
from streamlit_autorefresh import st_autorefresh

# =====================
# åŸºæœ¬è¨­å®š
# =====================
try:
    sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass

HK_TZ = pytz.timezone("Asia/Hong_Kong")

st.set_page_config(page_title="é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ", layout="wide", page_icon="ğŸ—ï¸")

# =====================
# CSSï¼ˆç™½åº•ç‰ˆï¼‰
# =====================
st.markdown(
    """
<style>
/* å…¨å±€å­—é«” */
html, body, [class*="css"]  { font-family: "Microsoft JhengHei","PingFang TC",sans-serif; }

/* æ¨™é¡Œ */
.section-title{
  font-size:1.05rem;
  font-weight:800;
  margin:2px 0 8px 0;
}

/* å¡ç‰‡ */
.card{
  background:#ffffff;
  border:1px solid #e5e7eb;
  border-radius:12px;
  padding:12px;
  height:520px;
  display:flex;
  flex-direction:column;
}

/* å…§éƒ¨æ»¾å‹• */
.items{
  overflow-y:auto;
  padding-right:6px;
  flex:1;
}

/* æ¯æ¢æ–°è */
.item{
  background:#ffffff;
  border-left:4px solid #3b82f6;
  border-radius:8px;
  padding:8px 10px;
  margin:8px 0;
}

.item a{
  text-decoration:none;
  color:#111827;
  font-weight:600;
  line-height:1.35;
  display:block;
}
.item a:hover{ color:#ef4444; }

.item-meta{
  font-size:0.78rem;
  color:#6b7280;
  font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  margin-top:2px;
}

.badge{
  display:inline-block;
  font-size:0.72rem;
  padding:2px 8px;
  border-radius:999px;
  background:#f3f4f6;
  color:#374151;
  margin-left:8px;
}

.empty{
  color:#9ca3af;
  text-align:center;
  margin-top:20px;
}
</style>
""",
    unsafe_allow_html=True,
)

# =====================
# Model
# =====================
@dataclass
class Article:
    title: str
    link: str
    time_str: str
    color: str

# =====================
# Helpers
# =====================
def now_hk() -> datetime.datetime:
    return datetime.datetime.now(HK_TZ)

def clean_text(raw: str) -> str:
    raw = html.unescape(raw or "")
    soup = BeautifulSoup(raw, "html.parser")
    return soup.get_text(" ", strip=True)

def _safe_get_bytes(url: str, timeout: int = 12) -> bytes:
    """
    ç”¨ requests æŠ“ RSS/XMLï¼ˆæ¯” feedparser ç›´æ¥ parse URL æ›´ç©©å®šï¼‰
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (NewsAggregator/1.0; +https://streamlit.io)",
        "Accept": "application/xml,text/xml,application/rss+xml,application/atom+xml,text/html,*/*",
    }
    r = requests.get(url, headers=headers, timeout=timeout)
    r.raise_for_status()
    return r.content

def _safe_get_json(url: str, params: Optional[dict] = None, timeout: int = 12) -> Any:
    headers = {
        "User-Agent": "Mozilla/5.0 (NewsAggregator/1.0; +https://streamlit.io)",
        "Accept": "application/json,text/plain,*/*",
    }
    r = requests.get(url, params=params, headers=headers, timeout=timeout)
    r.raise_for_status()
    return r.json()

def parse_rss_time(entry) -> Optional[datetime.datetime]:
    # feedparser æ¨™æº–æ¬„ä½
    if getattr(entry, "published_parsed", None):
        return datetime.datetime(*entry.published_parsed[:6], tzinfo=pytz.utc).astimezone(HK_TZ)
    if getattr(entry, "updated_parsed", None):
        return datetime.datetime(*entry.updated_parsed[:6], tzinfo=pytz.utc).astimezone(HK_TZ)

    # æ–‡å­—æ¬„ä½å˜—è©¦ parse
    for key in ("published", "updated", "pubDate", "date"):
        val = getattr(entry, key, None)
        if val:
            try:
                dt = dtparser.parse(str(val))
                if dt.tzinfo is None:
                    dt = HK_TZ.localize(dt)
                return dt.astimezone(HK_TZ)
            except Exception:
                pass
    return None

def _chunk(lst: List[dict], n: int) -> List[List[dict]]:
    return [lst[i:i+n] for i in range(0, len(lst), n)]

# =====================
# Fetchers
# =====================
@st.cache_data(ttl=60)
def fetch_rss_today(url: str, color: str, limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    RSSï¼šå„ªå…ˆåªé¡¯ç¤ºã€Œä»Šæ—¥ã€ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰
    - æœ‰æ™‚é–“ï¼šHH:MM
    - ç„¡æ™‚é–“ï¼šé¡¯ç¤ºã€Œä»Šæ—¥ã€ï¼ˆfallbackï¼‰
    - è‹¥ RSS è®€å–å¤±æ•—ï¼çµæ§‹æ€ªï¼šå›å‚³ error
    """
    today = now_hk().date()
    try:
        raw = _safe_get_bytes(url, timeout=12)
        feed = feedparser.parse(raw)

        dated: List[Article] = []
        undated: List[Article] = []

        for e in feed.entries or []:
            title = clean_text(getattr(e, "title", ""))
            link = getattr(e, "link", "")
            if not title or not link:
                continue

            dt = parse_rss_time(e)
            if dt and dt.date() == today:
                dated.append(Article(title, link, dt.strftime("%H:%M"), color))
            elif not dt:
                # ç„¡æ³•åˆ¤æ–·æ—¥æœŸï¼šå…ˆç•¶ä½œå¯ç”¨å€™é¸
                undated.append(Article(title, link, "ä»Šæ—¥", color))

        if dated:
            return dated[:limit], None

        if undated:
            return undated[:limit], "æ­¤ä¾†æºæœªæä¾›å¯è§£ææ™‚é–“ï¼Œå·²é¡¯ç¤ºæœ€æ–°æ¢ç›®ä¸¦ä»¥ã€Œä»Šæ—¥ã€æ¨™è¨˜"

        return [], None

    except Exception as e:
        return [], f"è®€å–å¤±æ•—ï¼š{type(e).__name__}: {e}"

@st.cache_data(ttl=60)
def fetch_rss_latest(url: str, color: str, limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    RSSï¼šæ°¸é é¡¯ç¤ºæœ€æ–°ï¼ˆå””åšä»Šæ—¥éæ¿¾ï¼‰
    """
    try:
        raw = _safe_get_bytes(url, timeout=12)
        feed = feedparser.parse(raw)

        out: List[Article] = []
        for e in (feed.entries or [])[:limit]:
            title = clean_text(getattr(e, "title", ""))
            link = getattr(e, "link", "")
            if not title or not link:
                continue

            dt = parse_rss_time(e)
            time_str = dt.strftime("%H:%M") if dt else "å³æ™‚"
            out.append(Article(title, link, time_str, color))

        return out, None

    except Exception as e:
        return [], f"è®€å–å¤±æ•—ï¼š{type(e).__name__}: {e}"

# =====================
# NOWï¼ˆæœ¬åœ°ï¼‰APIï¼šä½ æä¾›çš„ endpoint + æ­£ç¢ºè™•ç†æ¯«ç§’ timestamp
# =====================
NOW_API = "https://newsapi1.now.com/pccw-news-api/api/getNewsListv2"

@st.cache_data(ttl=60)
def fetch_now_local_today(color: str, limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    Now æ–°èï¼ˆæœ¬åœ°ï¼‰ï¼š
    - category=119
    - åªé¡¯ç¤ºä»Šæ—¥ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰
    - publishDate ä¿‚æ¯«ç§’ timestamp â†’ å¿…é ˆ fromtimestamp(ts/1000)
    - ä»Šæ—¥ç¯©é¸ç‚º 0 æ™‚ï¼Œfallback é¡¯ç¤ºæœ€æ–° 10ï¼ˆä¸¦æç¤ºï¼‰
    """
    today = now_hk().date()
    out_today: List[Article] = []
    out_latest: List[Article] = []

    try:
        data = _safe_get_json(NOW_API, params={"category": 119, "pageNo": 1}, timeout=12)

        # ä½ è²¼å‡ºä¾†çš„æ ¼å¼ä¿‚ list ç›´æ¥åŒ…ä½ dict
        candidates = None
        if isinstance(data, list):
            candidates = data
        elif isinstance(data, dict):
            # ä¿å®ˆæƒ key
            for k in ("data", "list", "news", "items", "result"):
                v = data.get(k)
                if isinstance(v, list):
                    candidates = v
                    break
            if candidates is None:
                for v in data.values():
                    if isinstance(v, list):
                        candidates = v
                        break

        if not candidates:
            return [], "Now API å›å‚³çµæ§‹å·²è®Šï¼ˆæ‰¾ä¸åˆ°æ–°èåˆ—è¡¨ï¼‰"

        for it in candidates:
            if not isinstance(it, dict):
                continue

            title = clean_text(str(it.get("title") or it.get("newsTitle") or it.get("storyTitle") or ""))
            # Now æœ‰æ™‚å†‡ webUrl/shareUrlï¼šç”¨ player?newsId=XXXX å…œåº•
            link = str(it.get("webUrl") or it.get("shareUrl") or it.get("url") or "")
            news_id = it.get("newsId") or it.get("id")

            if not link and news_id:
                link = f"https://news.now.com/home/local/player?newsId={news_id}"
            if link.startswith("/"):
                link = "https://news.now.com" + link

            raw_time = it.get("publishDate") or it.get("publishTime") or it.get("publishedAt") or it.get("date")

            dt = None
            time_str = "ä»Šæ—¥"
            if raw_time is not None:
                try:
                    # publishDate = 1767049974000ï¼ˆæ¯«ç§’ï¼‰
                    if isinstance(raw_time, (int, float)) or str(raw_time).isdigit():
                        ts = int(raw_time)
                        if ts > 1_000_000_000_000:  # > 1e12 è¦–ç‚ºæ¯«ç§’
                            ts = ts / 1000
                        dt = datetime.datetime.fromtimestamp(ts, tz=HK_TZ)
                    else:
                        dt = dtparser.parse(str(raw_time))
                        if dt.tzinfo is None:
                            dt = HK_TZ.localize(dt)
                        dt = dt.astimezone(HK_TZ)

                    time_str = dt.strftime("%H:%M")
                except Exception:
                    dt = None
                    time_str = "ä»Šæ—¥"

            if title and link:
                art = Article(title=title, link=link, time_str=time_str, color=color)
                out_latest.append(art)
                if dt and dt.date() == today:
                    out_today.append(art)

            if len(out_latest) >= limit:
                break

        if out_today:
            return out_today[:limit], None

        if out_latest:
            return out_latest[:limit], "æœªèƒ½ç¯©å‡ºã€ä»Šæ—¥ã€æ–°èï¼Œå·²æ”¹ç‚ºé¡¯ç¤ºæœ€æ–° 10 æ¢ï¼ˆè«‹ç¢ºèª Now API æ™‚é–“æ¬„ä½ï¼‰"

        return [], "Now API æœ‰å›å‚³ä½†æœªèƒ½è§£æåˆ°æœ‰æ•ˆæ–°èé …ç›®"

    except Exception as e:
        return [], f"Now API è®€å–å¤±æ•—ï¼š{type(e).__name__}: {e}"

# =====================
# Renderï¼ˆä¸€æ¬¡æ€§è¼¸å‡ºï¼Œé¿å… DOM æ–·è£‚ï¼‰
# =====================
def build_card_html(title: str, articles: List[Article], note: Optional[str] = None) -> str:
    if not articles:
        items_html = "<div class='empty'>ä»Šæ—¥æš«ç„¡æ–°è</div>"
    else:
        parts = []
        for a in articles:
            parts.append(
                f"""
                <div class="item" style="border-left-color:{a.color}">
                  <a href="{a.link}" target="_blank" rel="noopener noreferrer">{html.escape(a.title)}</a>
                  <div class="item-meta">ğŸ• {html.escape(a.time_str)}</div>
                </div>
                """
            )
        items_html = "".join(parts)

    badge = f"""<span class="badge">{html.escape(note)}</span>""" if note else ""
    return f"""
    <div class="section-title">{html.escape(title)}{badge}</div>
    <div class="card">
      <div class="items">
        {items_html}
      </div>
    </div>
    """

# =====================
# Sourcesï¼ˆä½ è¦æ±‚ï¼šå””å¥½æˆ‘è‡ªå·±æ€ï¼‰
# =====================
# ä½ ä¹‹å‰ç”¨éå˜… RSSHub baseï¼ˆå…ˆæ”¾é è¨­ï¼›ä½ å¯åœ¨å´æ¬„è¼¸å…¥è¦†è“‹ï¼‰
DEFAULT_RSSHUB_BASE = "https://rsshub-production-9dfc.up.railway.app"

GOV_ZH = "https://www.info.gov.hk/gia/rss/general_zh.xml"
GOV_EN = "https://www.info.gov.hk/gia/rss/general_en.xml"
RTHK = "https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml"

# =====================
# UI
# =====================
st.title("ğŸ—ï¸ é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ")
st.caption(f"æœ€å¾Œæ›´æ–°ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰ï¼š{now_hk().strftime('%Y-%m-%d %H:%M:%S')}")

with st.sidebar:
    st.subheader("è¨­å®š")
    rsshub_base = st.text_input("RSSHub Base URL", value=DEFAULT_RSSHUB_BASE).strip().rstrip("/")
    auto = st.toggle("æ¯åˆ†é˜è‡ªå‹•æ›´æ–°", value=True)
    strict_today = st.toggle("RSS åªé¡¯ç¤ºä»Šæ—¥", value=True)
    st.caption("æç¤ºï¼šNow ä½¿ç”¨å®˜æ–¹ APIï¼ˆcategory=119ï¼‰ï¼Œä¸èµ° RSSHubã€‚")

if auto:
    st_autorefresh(interval=60_000, key="auto")

# ä½ è¦çš„åª’é«”æ¸…å–®ï¼ˆå®˜æ–¹ + RSSHub + Now APIï¼‰
# type:
# - "rss_today": RSSï¼ˆåªé¡¯ç¤ºä»Šæ—¥ï¼‰
# - "rss_latest": RSSï¼ˆæœ€æ–°ï¼‰
# - "now_api_today": Nowï¼ˆä»Šæ—¥ / fallback latestï¼‰
SOURCES: List[Dict[str, Any]] = [
    {"name": "æ”¿åºœæ–°èï¼ˆä¸­æ–‡ï¼‰", "type": "rss_today", "url": GOV_ZH, "color": "#E74C3C"},
    {"name": "æ”¿åºœæ–°èï¼ˆè‹±æ–‡ï¼‰", "type": "rss_today", "url": GOV_EN, "color": "#C0392B"},
    {"name": "RTHK", "type": "rss_today", "url": RTHK, "color": "#FF9800"},

    # Nowï¼šRSSHub å£ -> ç”¨ API
    {"name": "Now æ–°èï¼ˆæœ¬åœ°ï¼‰", "type": "now_api_today", "color": "#2563EB"},

    # ä½ åˆ—å‡ºçš„ RSSHub é¦™æ¸¯åª’é«”
    {"name": "HK01", "type": "rss_latest", "url": f"{rsshub_base}/hk01/latest", "color": "#7C3AED"},
    {"name": "on.cc æ±ç¶²", "type": "rss_latest", "url": f"{rsshub_base}/oncc/zh-hant/news", "color": "#0EA5E9"},
    {"name": "TVB æ–°è", "type": "rss_latest", "url": f"{rsshub_base}/tvb/news/tc", "color": "#1D4ED8"},
    {"name": "ä¿¡å ±å³æ™‚ (hkej)", "type": "rss_latest", "url": f"{rsshub_base}/hkej/index", "color": "#111827"},
    {"name": "æ˜Ÿå³¶å³æ™‚", "type": "rss_latest", "url": f"{rsshub_base}/stheadline/std/realtime", "color": "#16A34A"},
    {"name": "i-CABLE æœ‰ç·š", "type": "rss_latest", "url": f"{rsshub_base}/icable/all", "color": "#F97316"},

    # æ˜å ±ï¼šä½ è©±ã€Œå®˜æ–¹ RSSã€ï¼Œä½†ä½ æœªæä¾› URLï¼›å””æœƒäº‚çŒœã€‚
    # ä½ æä¾›å’— URL æˆ‘å†å¹«ä½ åŠ è¿”å»ã€‚
    # {"name": "æ˜å ±", "type": "rss_latest", "url": "ï¼ˆè«‹å¡«å…¥æ˜å ±å®˜æ–¹ RSSï¼‰", "color": "#DC2626"},
]

# =====================
# å–æ•¸ï¼ˆé€å€‹ sourceï¼‰
# =====================
def get_articles(src: Dict[str, Any]) -> Tuple[List[Article], Optional[str]]:
    t = src["type"]
    color = src["color"]

    if t == "now_api_today":
        return fetch_now_local_today(color=color, limit=10)

    url = src.get("url", "")
    if not url:
        return [], "æœªè¨­å®š URL"

    if strict_today and t == "rss_today":
        return fetch_rss_today(url=url, color=color, limit=10)

    # é strictï¼šç”¨ latest
    return fetch_rss_latest(url=url, color=color, limit=10)

# =====================
# æ’ç‰ˆï¼šä¿æŒã€Œæ©«å‘ä¸¦åˆ—ã€ï¼›æ¯è¡Œ 4 æ ¼ï¼ˆä½ å¯æ”¹ï¼‰
# =====================
PER_ROW = 4
rows = _chunk(SOURCES, PER_ROW)

for row in rows:
    cols = st.columns(len(row))
    for i, src in enumerate(row):
        arts, note = get_articles(src)
        with cols[i]:
            st.markdown(build_card_html(src["name"], arts, note), unsafe_allow_html=True)
