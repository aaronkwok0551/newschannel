# -*- coding: utf-8 -*-
import streamlit as st
import requests
import feedparser
import datetime
import pytz
import urllib.parse
import time
from bs4 import BeautifulSoup
import sys
from streamlit_autorefresh import st_autorefresh

# è¨­å®šé è¨­ç·¨ç¢¼
try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass

# --- 1. é é¢èˆ‡è‡ªå®šç¾©æ¨£å¼ (å«é–ƒçˆç‰¹æ•ˆ) ---
st.set_page_config(
    page_title="Tommy Sir å¾Œæ´æœƒä¹‹æ–°èç›£å¯Ÿç³»çµ±",
    page_icon="ğŸ“°",
    layout="wide"
)

# è‡ªå‹•åˆ·æ–° (æ¯ 60 ç§’)
st_autorefresh(interval=60 * 1000, limit=None, key="news_autoupdate")

st.markdown("""
<style>
    /* é–ƒçˆç‰¹æ•ˆ */
    @keyframes blinker {
        50% { opacity: 0; }
    }
    .new-badge {
        color: #ff4b4b;
        font-weight: bold;
        animation: blinker 1s linear infinite;
        margin-right: 5px;
        font-size: 0.8em;
    }
    .read-text {
        color: #a0a0a0 !important;
        text-decoration: none;
        font-weight: normal !important;
    }
    .stCheckbox { margin-bottom: 0px; }
    .news-source-header { 
        font-size: 1.2em; 
        font-weight: bold; 
        color: #1e293b; 
        margin-top: 15px; 
        margin-bottom: 10px;
        padding-bottom: 5px;
        border-bottom: 2px solid #ddd;
    }
    a { text-decoration: none; color: #2980b9; transition: 0.3s; }
    a:hover { color: #e74c3c; }
    div[data-testid="column"] { display: flex; align-items: start; }
    .generated-box {
        background-color: #f8fafc;
        padding: 20px;
        border-radius: 12px;
        border: 1px solid #e2e8f0;
        margin-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

# è¨­å®šæ™‚å€
HK_TZ = pytz.timezone('Asia/Hong_Kong')
UTC_TZ = pytz.timezone('UTC')

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
}

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

def fetch_full_article(url):
    """ æŠ“å–å®Œæ•´çš„æ­£æ–‡å…§å®¹ï¼Œé‡å°ä¸åŒå¹³å°å„ªåŒ– """
    try:
        r = requests.get(url, headers=HEADERS, timeout=8)
        r.encoding = 'utf-8'
        soup = BeautifulSoup(r.text, 'html.parser')
        
        # ç§»é™¤ä¸å¿…è¦çš„å…ƒç´ 
        for tag in soup(['script', 'style', 'header', 'footer', 'nav', 'iframe']):
            tag.decompose()

        # å˜—è©¦æŠ“å–æ­£æ–‡å€åŸŸ (é‡å° TVB/Now/HK01 ç­‰å¸¸è¦‹çµæ§‹)
        # 1. å„ªå…ˆå˜—è©¦å¸¸è¦‹çš„æ–‡ç« å®¹å™¨
        content_area = soup.find('div', class_=lambda x: x and ('article' in x.lower() or 'content' in x.lower() or 'news-text' in x.lower()))
        
        if content_area:
            paragraphs = content_area.find_all(['p', 'div'], recursive=False)
        else:
            paragraphs = soup.find_all('p')

        if not paragraphs:
            return "ç„¡æ³•è‡ªå‹•æå–å…¨æ–‡å…§å®¹ï¼Œè«‹é»æ“Šé€£çµæŸ¥çœ‹ç¶²é ç‰ˆã€‚"
            
        full_text = "\n".join([p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > 10])
        return full_text if len(full_text) > 30 else "æŠ“å–å…§å®¹éçŸ­ï¼Œå¯èƒ½å—é™æ–¼ç¶²é æ¬Šé™æˆ–å‹•æ…‹è¼‰å…¥ã€‚"
    except Exception as e:
        return f"å…¨æ–‡æŠ“å–å¤±æ•—: {str(e)}"

def resolve_google_url(url):
    if "news.google.com" not in url:
        return url
    try:
        r = requests.head(url, headers=HEADERS, allow_redirects=True, timeout=5)
        return r.url
    except:
        return url

def is_new_news(published_time_str):
    """ åˆ¤æ–·æ˜¯å¦ç‚º 15 åˆ†é˜å…§çš„æ–°è """
    try:
        pub_time = datetime.datetime.strptime(published_time_str, '%Y-%m-%d %H:%M')
        pub_time = HK_TZ.localize(pub_time)
        now = datetime.datetime.now(HK_TZ)
        diff = (now - pub_time).total_seconds() / 60
        return 0 <= diff <= 15
    except:
        return False

@st.cache_data(ttl=60)
def fetch_news_data(func_name, *args):
    """ é›†ä¸­è™•ç†æŠ“å–æ•¸æ“šä¸¦å¿«å– """
    if func_name == "fetch_hk01":
        return fetch_hk01()
    elif func_name == "fetch_google_rss":
        return fetch_google_rss(*args)
    elif func_name == "fetch_direct_rss":
        return fetch_direct_rss(*args)
    return []

def fetch_google_rss(site_domain, site_name, color):
    query = urllib.parse.quote(f"site:{site_domain}")
    rss_url = f"https://news.google.com/rss/search?q={query}+when:1d&hl=zh-HK&gl=HK&ceid=HK:zh-Hant"
    feed = feedparser.parse(rss_url)
    news = []
    for entry in feed.entries[:8]:
        title = entry.title.rsplit(" - ", 1)[0] if " - " in entry.title else entry.title
        dt_str = ""
        if hasattr(entry, 'published_parsed'):
            dt_obj = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed), UTC_TZ).astimezone(HK_TZ)
            dt_str = dt_obj.strftime('%Y-%m-%d %H:%M')
        news.append({'source': site_name, 'title': title, 'link': entry.link, 'time': dt_str, 'color': color})
    return news

def fetch_direct_rss(url, name, color):
    try:
        r = requests.get(url, headers=HEADERS, timeout=5)
        feed = feedparser.parse(r.content)
        news = []
        for entry in feed.entries[:8]:
            dt_str = ""
            if hasattr(entry, 'published_parsed'):
                dt_obj = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed), UTC_TZ).astimezone(HK_TZ)
                dt_str = dt_obj.strftime('%Y-%m-%d %H:%M')
            link = entry.link
            # ä¿®æ­£ Now é€£çµ
            if 'news.now.com' in url and 'news.now.com' not in link:
                link = f"https://news.now.com{link}"
            news.append({'source': name, 'title': entry.title, 'link': link, 'time': dt_str, 'color': color})
        return news
    except: return []

def fetch_hk01():
    try:
        r = requests.get("https://web-data.api.hk01.com/v2/feed/category/0", headers=HEADERS, timeout=5)
        items = r.json().get('items', [])[:8]
        news = []
        for item in items:
            raw = item.get('data', {})
            dt_str = datetime.datetime.fromtimestamp(raw.get('publishTime'), HK_TZ).strftime('%Y-%m-%d %H:%M')
            news.append({'source': "HK01", 'title': raw.get('title'), 'link': raw.get('publishUrl'), 'time': dt_str, 'color': "#184587"})
        return news
    except: return []

# --- 3. åˆå§‹åŒ–ç‹€æ…‹ ---

if 'selected_links' not in st.session_state:
    st.session_state.selected_links = set()
if 'generated_text' not in st.session_state:
    st.session_state.generated_text = ""
if 'all_current_news' not in st.session_state:
    st.session_state.all_current_news = []

# --- 4. å´é‚Šæ¬„æ§åˆ¶ ---

with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±æ§åˆ¶")
    if st.button("ğŸ”„ ç«‹å³åˆ·æ–°æ‰€æœ‰æ–°è"):
        st.cache_data.clear()
        st.session_state.all_current_news = []
        st.rerun()
    
    st.divider()
    st.write(f"ç›®å‰å·²é¸æ“‡: **{len(st.session_state.selected_links)}** ç¯‡")
    
    if st.button("ğŸ“„ ç”Ÿæˆ TXT å…§å®¹", type="primary"):
        if not st.session_state.selected_links:
            st.warning("è«‹å…ˆå‹¾é¸æ–°è")
        else:
            with st.spinner("æ­£åœ¨é€ä¸€æŠ“å–å…¨æ–‡ä¸­ï¼Œè«‹ç¨å€™..."):
                final_txt = ""
                # ä½¿ç”¨å­˜å„²åœ¨ session_state ä¸­çš„æ•¸æ“šé€²è¡Œç”Ÿæˆ
                selected_news = [item for item in st.session_state.all_current_news if item['link'] in st.session_state.selected_links]
                
                for item in selected_news:
                    real_url = resolve_google_url(item['link'])
                    content = fetch_full_article(real_url)
                    final_txt += f"{item['source']}ï¼š{item['title']}\n"
                    final_txt += f"[{item['time']}]\n\n"
                    final_txt += f"{content}\n\n"
                    final_txt += f"{real_url}\n\n"
                    final_txt += "Ends\n\n"
                st.session_state.generated_text = final_txt
    
    if st.button("ğŸ—‘ï¸ å–æ¶ˆæ‰€æœ‰é¸æ“‡ / æ¸…ç©º"):
        st.session_state.selected_links.clear()
        st.session_state.generated_text = ""
        st.rerun()

# --- 5. UI ä»‹é¢èˆ‡å…§å®¹é¡¯ç¤º ---

st.title("Tommy Sir å¾Œæ´æœƒä¹‹æ–°èç›£å¯Ÿç³»çµ±")
st.caption(f"æœ€å¾ŒåŒæ­¥æ™‚é–“: {datetime.datetime.now(HK_TZ).strftime('%Y-%m-%d %H:%M:%S')}")

# ç”Ÿæˆå…§å®¹é¡¯ç¤ºå€åŸŸ (ç›´æ¥é¡¯ç¤ºåœ¨ä¸»ç¶²é )
if st.session_state.generated_text:
    st.markdown("### ğŸ“„ ç”Ÿæˆå…§å®¹é è¦½")
    st.text_area("æ‚¨å¯ä»¥ç›´æ¥è¤‡è£½ä¸‹æ–¹å…§å®¹ï¼š", value=st.session_state.generated_text, height=450)
    if st.button("âŒ é—œé–‰é è¦½"):
        st.session_state.generated_text = ""
        st.rerun()
    st.divider()

# æ–°èæŠ“å–ä¾†æºé…ç½® (å®Œæ•´ 6 å€‹å¹³å°)
sources_config = [
    ("HK01", "fetch_hk01", []),
    ("ç„¡ç·šæ–°è", "fetch_google_rss", ["news.tvb.com/tc/local", "ç„¡ç·šæ–°è", "#27ae60"]),
    ("Now æ–°è", "fetch_google_rss", ["news.now.com/home/local", "Now æ–°è", "#E65100"]),
    ("é¦™æ¸¯é›»å°", "fetch_direct_rss", ["https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml", "é¦™æ¸¯é›»å°", "#FF9800"]),
    ("æœ‰ç·šæ–°è", "fetch_direct_rss", ["https://www.i-cable.com/feed/", "æœ‰ç·šæ–°è", "#c0392b"]),
    ("å•†å° 881903", "fetch_google_rss", ["881903.com", "å•†å°", "#F1C40F"]),
]

cols = st.columns(3)
temp_all_news = [] # æš«å­˜æœ¬æ¬¡æŠ“å–çš„æ•¸æ“š

for i, (name, func_name, args) in enumerate(sources_config):
    with cols[i % 3]:
        news_items = fetch_news_data(func_name, *args)
        temp_all_news.extend(news_items)
        
        st.markdown(f"<div class='news-source-header'>{name}</div>", unsafe_allow_html=True)
        
        if not news_items:
            st.write("æš«ç„¡æ›´æ–°")
        else:
            for item in news_items:
                link = item['link']
                is_new = is_new_news(item['time'])
                is_selected = link in st.session_state.selected_links
                
                # UI æ’ç‰ˆ
                c1, c2 = st.columns([0.15, 0.85])
                with c1:
                    # å‹¾é¸æ¡†
                    if st.checkbox("", key=f"chk_{link}", value=is_selected):
                        st.session_state.selected_links.add(link)
                    else:
                        st.session_state.selected_links.discard(link)
                
                with c2:
                    new_tag = '<span class="new-badge">NEW!</span>' if is_new else ''
                    text_style = 'class="read-text"' if is_selected else ""
                    st.markdown(f"""
                        {new_tag}
                        <a href="{link}" target="_blank" {text_style}>
                            <b>{item['title']}</b>
                        </a><br>
                        <small style="color:gray;">{item['time']}</small>
                    """, unsafe_allow_html=True)

# å°‡æœ¬æ¬¡æŠ“å–çš„æ•¸æ“šå­˜å…¥ session_stateï¼Œä¾› sidebar ç”ŸæˆæŒ‰éˆ•ä½¿ç”¨
st.session_state.all_current_news = temp_all_news
