# -*- coding: utf-8 -*-
import streamlit as st
import feedparser
import datetime
import pytz
import re
from bs4 import BeautifulSoup
import sys

# è¨­å®šé è¨­ç·¨ç¢¼
try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass

# --- 1. é é¢åŸºæœ¬è¨­å®š ---
st.set_page_config(
    page_title="é¦™æ¸¯æ–°èèšåˆ",
    layout="wide",
    page_icon="ğŸ“°"
)

# --- 2. CSS æ¨£å¼ ---
st.markdown("""
<style>
    body { 
        font-family: "Microsoft JhengHei", "PingFang TC", sans-serif; 
    }
    
    .news-source-header { 
        font-size: 1.3em; 
        font-weight: bold; 
        color: #1e293b; 
        margin-top: 20px; 
        margin-bottom: 15px;
        padding: 10px 15px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .news-item {
        padding: 12px 15px;
        margin-bottom: 10px;
        background: white;
        border-left: 4px solid #3498db;
        border-radius: 6px;
        transition: all 0.3s ease;
        box-shadow: 0 1px 3px rgba(0,0,0,0.08);
    }
    
    .news-item:hover {
        transform: translateX(5px);
        box-shadow: 0 3px 8px rgba(0,0,0,0.15);
        border-left-color: #e74c3c;
    }
    
    .news-title {
        font-size: 1.05rem;
        font-weight: 500;
        color: #2c3e50;
        text-decoration: none;
        line-height: 1.5;
        display: block;
        margin-bottom: 5px;
    }
    
    .news-title:hover {
        color: #e74c3c;
    }
    
    .news-time {
        font-size: 0.85rem;
        color: #7f8c8d;
        font-family: monospace;
    }
    
    .gov-section {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 20px;
        border-radius: 12px;
        margin-bottom: 30px;
    }
    
    .media-section {
        background: #f8f9fa;
        padding: 20px;
        border-radius: 12px;
    }
    
    /* æ¬„ä½å®¹å™¨æ¨£å¼ */
    div[data-testid="column"] {
        background: white;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.05);
        margin: 5px;
    }
    
    h3 {
        color: #2c3e50;
        font-weight: 600;
        margin-bottom: 20px;
        padding-bottom: 10px;
        border-bottom: 3px solid #3498db;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. å·¥å…·å‡½æ•¸ ---
hk_tz = pytz.timezone('Asia/Hong_Kong')

def clean_html_title(raw_html):
    """æ¸…é™¤æ¨™é¡Œä¸­çš„ HTML æ¨™ç±¤"""
    if not raw_html:
        return ""
    soup = BeautifulSoup(raw_html, "html.parser")
    text = soup.get_text()
    cleanr = re.compile('<.*?>')
    text = re.sub(cleanr, '', text)
    return " ".join(text.split())

def parse_single_feed(source_name, url, color, filter_today=False, max_items=10):
    """è®€å–å–®å€‹ RSS ä¾†æº"""
    articles = []
    now_hk = datetime.datetime.now(hk_tz)

    try:
        feed = feedparser.parse(url)
        if not feed.entries:
            return articles

        for entry in feed.entries[:max_items]:
            dt_obj = None
            time_str = ""
            
            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                dt_utc = datetime.datetime(*entry.published_parsed[:6], tzinfo=pytz.utc)
                dt_hk = dt_utc.astimezone(hk_tz)
                dt_obj = dt_hk
                time_str = dt_hk.strftime('%H:%M')
            else:
                dt_obj = now_hk
                time_str = "--:--"

            if filter_today:
                if dt_obj.date() != now_hk.date():
                    continue

            title_clean = clean_html_title(entry.title)
            
            articles.append({
                'source': source_name,
                'title': title_clean,
                'link': entry.link,
                'time': time_str,
                'timestamp': dt_obj,
                'color': color
            })
    except Exception as e:
        print(f"Error fetching {source_name}: {e}")

    articles.sort(key=lambda x: x['timestamp'], reverse=True)
    return articles

def render_news_items(articles):
    """æ¸²æŸ“æ–°èé …ç›®ç‚º HTML"""
    if not articles:
        return "<p style='color:#95a5a6; padding:15px; text-align:center;'>æš«ç„¡æ–°è</p>"
    
    html = ""
    for art in articles:
        html += f"""
        <div class="news-item">
            <a href="{art['link']}" target="_blank" class="news-title">
                {art['title']}
            </a>
            <span class="news-time">ğŸ• {art['time']}</span>
        </div>
        """
    return html

# --- 4. å®šç¾©æ–°èä¾†æº ---
gov_feeds = [
    ("æ”¿åºœæ–°è (ä¸­)", "https://www.info.gov.hk/gia/rss/general_zh.xml", "#E74C3C"),
    ("Gov News (En)", "https://www.info.gov.hk/gia/rss/general_en.xml", "#C0392B")
]

media_feeds = [
    ("TVB æ–°è", "https://news.tvb.com/rss/local.xml", "#2ECC71"),
    ("Now æ–°è", "https://news.now.com/rss/local", "#3498DB"),
    ("å•†å° 903", "https://news.google.com/rss/search?q=%E5%8F%B1%E5%90%92903&hl=zh-HK&gl=HK&ceid=HK:zh-Hant", "#F1C40F"),
    ("é¦™æ¸¯é›»å°", "https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml", "#FF9800"),
    ("æœ‰ç·šæ–°è", "https://www.i-cable.com/feed/", "#c0392b"),
    ("HK01", "https://web-data.api.hk01.com/v2/feed/category/0", "#184587")
]

# --- 5. ä¸»ç¨‹å¼ä»‹é¢ ---
st.title("ğŸ—ï¸ é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ")
st.caption(f"æœ€å¾Œæ›´æ–°: {datetime.datetime.now(hk_tz).strftime('%Y-%m-%d %H:%M:%S')}")

if st.button("ğŸ”„ åˆ·æ–°æ–°è", type="primary"):
    st.rerun()

st.divider()

# --- æ”¿åºœæ–°èç¨¿å€å¡Š ---
st.markdown('<div class="gov-section">', unsafe_allow_html=True)
st.markdown("### ğŸ›ï¸ æ”¿åºœæ–°èç¨¿ (åƒ…é™ä»Šæ—¥)")

col1, col2 = st.columns(2)

with col1:
    st.markdown('<div class="news-source-header">ğŸ“„ ä¸­æ–‡ç‰ˆ</div>', unsafe_allow_html=True)
    with st.spinner('è®€å–ä¸­...'):
        zh_articles = parse_single_feed(
            gov_feeds[0][0], 
            gov_feeds[0][1], 
            gov_feeds[0][2], 
            filter_today=True,
            max_items=15
        )
        st.markdown(render_news_items(zh_articles), unsafe_allow_html=True)

with col2:
    st.markdown('<div class="news-source-header">ğŸ“„ English</div>', unsafe_allow_html=True)
    with st.spinner('è®€å–ä¸­...'):
        en_articles = parse_single_feed(
            gov_feeds[1][0], 
            gov_feeds[1][1], 
            gov_feeds[1][2], 
            filter_today=True,
            max_items=15
        )
        st.markdown(render_news_items(en_articles), unsafe_allow_html=True)

st.markdown('</div>', unsafe_allow_html=True)

st.divider()

# --- åª’é«”å ±å°å€å¡Š ---
st.markdown('<div class="media-section">', unsafe_allow_html=True)
st.markdown("### ğŸ“º åª’é«”å ±å°")

# å‰µå»º 3x2 ç¶²æ ¼ä½ˆå±€
row1_cols = st.columns(3)
row2_cols = st.columns(3)

all_cols = [row1_cols[0], row1_cols[1], row1_cols[2], 
            row2_cols[0], row2_cols[1], row2_cols[2]]

for idx, (source_name, url, color) in enumerate(media_feeds):
    with all_cols[idx]:
        # æ ¹æ“šä¾†æºè¨­å®šä¸åŒçš„åœ–ç¤º
        icon_map = {
            "TVB æ–°è": "ğŸ“º",
            "Now æ–°è": "ğŸ“º",
            "å•†å° 903": "ğŸ“»",
            "é¦™æ¸¯é›»å°": "ğŸ“»",
            "æœ‰ç·šæ–°è": "ğŸ“º",
            "HK01": "ğŸ“±"
        }
        icon = icon_map.get(source_name, "ğŸ“°")
        
        st.markdown(f'<div class="news-source-header">{icon} {source_name}</div>', unsafe_allow_html=True)
        
        with st.spinner('è®€å–ä¸­...'):
            # HK01 éœ€è¦ç‰¹æ®Šè™•ç†
            if source_name == "HK01":
                # HK01 ä½¿ç”¨ APIï¼Œæš«æ™‚é¡¯ç¤ºä½”ä½ç¬¦
                st.markdown("<p style='color:#95a5a6; padding:15px; text-align:center;'>æš«ä¸æ”¯æ´ HK01</p>", unsafe_allow_html=True)
            else:
                articles = parse_single_feed(
                    source_name, 
                    url, 
                    color, 
                    filter_today=False,
                    max_items=10
                )
                st.markdown(render_news_items(articles), unsafe_allow_html=True)

st.markdown('</div>', unsafe_allow_html=True)
