# -*- coding: utf-8 -*-
import streamlit as st
import requests
import feedparser
import datetime
import pytz
import urllib.parse
import time
from bs4 import BeautifulSoup
import sys
from streamlit_autorefresh import st_autorefresh

# è¨­å®šé è¨­ç·¨ç¢¼
try:
    sys.stdout.reconfigure(encoding='utf-8')
except:
    pass

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="Tommy Sir å¾Œæ´æœƒä¹‹æ–°èç›£å¯Ÿç³»çµ±",
    page_icon="ğŸ“°",
    layout="wide"
)

# è‡ªå‹•åˆ·æ–° (æ¯ 60 ç§’)
st_autorefresh(interval=60 * 1000, limit=None, key="news_autoupdate")

# --- CSS æ¨£å¼ (ç§»æ¤è‡ª SPA è¨­è¨ˆ) ---
st.markdown("""
<style>
    /* é–ƒçˆç‰¹æ•ˆ - é‡å° 20 åˆ†é˜å…§çš„æ–°è */
    @keyframes blinker {
        50% { opacity: 0.4; }
    }
    .new-badge {
        color: #ef4444;
        font-weight: 800;
        animation: blinker 1.5s ease-in-out infinite;
        margin-right: 5px;
        font-size: 0.8em;
    }
    
    /* å·²è®€ç‹€æ…‹ */
    .read-text {
        color: #9ca3af !important;
        font-weight: normal !important;
        text-decoration: none !important;
    }
    
    /* é€£çµæ¨£å¼ */
    a { text-decoration: none; color: #1e293b; transition: 0.2s; }
    a:hover { color: #ef4444; }
    
    /* å¡ç‰‡æ¨™é¡Œ */
    .news-source-header { 
        font-size: 1.1em; 
        font-weight: bold; 
        color: #2c3e50; 
        margin-top: 10px; 
        margin-bottom: 10px;
        padding-bottom: 5px;
        border-bottom: 1px solid #e2e8f0;
        display: flex;
        justify-content: space-between;
        align-items: center;
    }
    
    /* ç‹€æ…‹æ¨™ç±¤ */
    .status-badge {
        font-size: 0.6em;
        padding: 2px 6px;
        border-radius: 4px;
        font-weight: normal;
        background-color: #f1f5f9;
        color: #64748b;
    }
    
    /* èª¿æ•´ Checkbox */
    .stCheckbox { margin-bottom: 0px; }
    div[data-testid="column"] { display: flex; align-items: start; }
    
    /* ç”Ÿæˆå…§å®¹å€åŸŸæ¨£å¼ (æ¨¡æ“¬ Popup) */
    .generated-box {
        border: 2px solid #3b82f6;
        border-radius: 12px;
        padding: 20px;
        background-color: #ffffff;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        margin-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

# è¨­å®šæ™‚å€
HK_TZ = pytz.timezone('Asia/Hong_Kong')
UTC_TZ = pytz.timezone('UTC')

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
}

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

def fetch_full_article(url):
    """ æŠ“å–æ–°èæ­£æ–‡ """
    try:
        r = requests.get(url, headers=HEADERS, timeout=6)
        r.encoding = 'utf-8'
        soup = BeautifulSoup(r.text, 'html.parser')
        
        for tag in soup(['script', 'style', 'header', 'footer', 'nav', 'iframe', 'noscript']):
            tag.decompose()

        # æ™ºæ…§æŠ“å–å¸¸è¦‹æ–‡ç« å®¹å™¨
        content_area = soup.find('div', class_=lambda x: x and ('article' in x.lower() or 'content' in x.lower() or 'news-text' in x.lower()))
        
        if content_area:
            paragraphs = content_area.find_all(['p', 'div'], recursive=False)
        else:
            paragraphs = soup.find_all('p')

        if not paragraphs:
            return "(ç„¡æ³•è‡ªå‹•æå–å…¨æ–‡ï¼Œè«‹é»æ“Šé€£çµæŸ¥çœ‹ç¶²é ç‰ˆ)"
            
        full_text = "\n".join([p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > 5])
        return full_text if len(full_text) > 30 else "(å…§å®¹éçŸ­æˆ–å—é™)"
    except:
        return "(å…¨æ–‡æŠ“å–å¤±æ•—)"

def is_new_news(time_str):
    """ åˆ¤æ–·æ˜¯å¦ç‚º 20 åˆ†é˜å…§çš„æ–°è """
    try:
        pub_time = datetime.datetime.strptime(time_str, '%Y-%m-%d %H:%M')
        pub_time = HK_TZ.localize(pub_time)
        now = datetime.datetime.now(HK_TZ)
        diff = (now - pub_time).total_seconds() / 60
        return 0 <= diff <= 20
    except:
        return False

# --- 3. æŠ“å–é‚è¼¯ (åªä½¿ç”¨ç›´é€£/RSSHub) ---

def fetch_rss_or_api(config):
    data = []
    try:
        if config['type'] == 'api_hk01':
            r = requests.get(config['url'], headers=HEADERS, timeout=8)
            items = r.json().get('items', [])[:10]
            for item in items:
                raw = item.get('data', {})
                dt_str = datetime.datetime.fromtimestamp(raw.get('publishTime'), HK_TZ).strftime('%Y-%m-%d %H:%M')
                data.append({'source': config['name'], 'title': raw.get('title'), 'link': raw.get('publishUrl'), 'time': dt_str, 'color': config['color']})
                
        elif config['type'] == 'api_now':
             # Now æ–°èç¶²é æŠ“å– (æ¯” RSS ç©©)
             r = requests.get(config['url'], headers=HEADERS, timeout=8)
             r.encoding = 'utf-8'
             soup = BeautifulSoup(r.text, 'html.parser')
             items = soup.select('.newsLeading') + soup.select('.news-list-item')
             for item in items[:10]:
                 link_tag = item.select_one('a')
                 if link_tag:
                     link = "https://news.now.com" + link_tag['href']
                     title = link_tag.get_text(strip=True)
                     data.append({'source': config['name'], 'title': title, 'link': link, 'time': "æœ€æ–°", 'color': config['color']})

        elif config['type'] == 'rss':
            r = requests.get(config['url'], headers=HEADERS, timeout=8)
            feed = feedparser.parse(r.content)
            for entry in feed.entries[:10]:
                dt_str = "æœ€æ–°"
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    dt_obj = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed), UTC_TZ).astimezone(HK_TZ)
                    dt_str = dt_obj.strftime('%Y-%m-%d %H:%M')
                data.append({'source': config['name'], 'title': entry.title, 'link': entry.link, 'time': dt_str, 'color': config['color']})

    except Exception as e:
        print(f"Error fetching {config['name']}: {e}")
        # å¤±æ•—æ™‚å›å‚³ç©ºåˆ—è¡¨ï¼Œä¸ä½¿ç”¨ Google Proxy
        data = []
    
    return data

@st.cache_data(ttl=60)
def get_all_news_data():
    """ ç²å–æ‰€æœ‰æ–°èä¸¦å¿«å– """
    # ä½¿ç”¨å…¬å…± RSSHub æˆ–æ‚¨è‡ªå·±çš„ Railway RSSHub URL
    # å¦‚æœæ‚¨çš„ Railway RSSHub URL æ˜¯å›ºå®šçš„ï¼Œè«‹æ›¿æ›ä¸‹é¢çš„ç¶²å€
    RSSHUB_BASE = "https://rsshub.app" 
    
    configs = [
        # ç¬¬ä¸€è¡Œ (4å€‹)
        {'name': 'æ”¿åºœæ–°è(ä¸­)', 'type': 'rss', 'url': 'https://www.info.gov.hk/gia/rss/general_zh.xml', 'color': '#E74C3C'},
        {'name': 'æ”¿åºœæ–°è(è‹±)', 'type': 'rss', 'url': 'https://www.info.gov.hk/gia/rss/general_en.xml', 'color': '#C0392B'},
        {'name': 'é¦™æ¸¯é›»å°', 'type': 'rss', 'url': 'https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml', 'color': '#FF9800'},
        {'name': 'Now æ–°è', 'type': 'api_now', 'url': 'https://news.now.com/home/local', 'color': '#2563EB'},
        
        # ç¬¬äºŒè¡Œ (4å€‹)
        {'name': 'HK01', 'type': 'api_hk01', 'url': 'https://web-data.api.hk01.com/v2/feed/category/0', 'color': '#0ea5e9'},
        {'name': 'æ±ç¶² on.cc', 'type': 'rss', 'url': f'{RSSHUB_BASE}/oncc/zh-hant/news', 'color': '#111827'},
        {'name': 'ç„¡ç·šæ–°è', 'type': 'rss', 'url': f'{RSSHUB_BASE}/tvb/news/tc', 'color': '#16a34a'},
        {'name': 'ä¿¡å ±', 'type': 'rss', 'url': f'{RSSHUB_BASE}/hkej/index', 'color': '#7c3aed'},
        
        # ç¬¬ä¸‰è¡Œ (4å€‹) - åŒ…å«æ˜Ÿå³¶å’Œæœ‰ç·š
        {'name': 'æ˜Ÿå³¶æ—¥å ±', 'type': 'rss', 'url': f'{RSSHUB_BASE}/stheadline/std/realtime', 'color': '#f97316'},
        {'name': 'æœ‰ç·šæ–°è', 'type': 'rss', 'url': f'{RSSHUB_BASE}/icable/all', 'color': '#dc2626'},
        # å¦‚æœ‰æ›´å¤šä¾†æºå¯ç¹¼çºŒæ·»åŠ 
    ]

    results_map = {}
    ordered_names = []
    
    for conf in configs:
        items = fetch_rss_or_api(conf)
        results_map[conf['name']] = items
        ordered_names.append(conf)
        
    return results_map, ordered_names

# --- 4. åˆå§‹åŒ– Session ---

if 'selected_links' not in st.session_state:
    st.session_state.selected_links = set()
if 'generated_text' not in st.session_state:
    st.session_state.generated_text = ""

# åŸ·è¡Œè³‡æ–™æŠ“å–
news_data_map, source_configs = get_all_news_data()

# å»ºç«‹æ‰å¹³åŒ–åˆ—è¡¨
all_flat_news = []
for name, items in news_data_map.items():
    all_flat_news.extend(items)

# --- 5. UI ä½ˆå±€ (Sidebar + Grid) ---

# å·¦å´å´é‚Šæ¬„
with st.sidebar:
    st.header("âš™ï¸ æ§åˆ¶å°")
    
    st.caption(f"æœ€å¾Œæ›´æ–°: {datetime.datetime.now(HK_TZ).strftime('%H:%M:%S')}")
    
    if st.button("ğŸ”„ ç«‹å³åˆ·æ–°", use_container_width=True):
        st.cache_data.clear()
        st.rerun()
    
    st.divider()
    
    select_count = len(st.session_state.selected_links)
    st.metric("å·²é¸æ–°è", f"{select_count} ç¯‡")
    
    # ç”ŸæˆæŒ‰éˆ•
    if st.button("ğŸ“„ ç”Ÿæˆ TXT å…§å®¹", type="primary", use_container_width=True):
        if select_count == 0:
            st.warning("è«‹å…ˆå‹¾é¸æ–°èï¼")
        else:
            with st.spinner("æ­£åœ¨æå–å…¨æ–‡..."):
                final_txt = ""
                targets = [n for n in all_flat_news if n['link'] in st.session_state.selected_links]
                
                for item in targets:
                    content = fetch_full_article(item['link'])
                    
                    final_txt += f"{item['source']}ï¼š{item['title']}\n"
                    final_txt += f"[{item['time']}]\n\n"
                    final_txt += f"{content}\n\n"
                    final_txt += f"{item['link']}\n\n"
                    final_txt += "Ends\n\n"
                
                st.session_state.generated_text = final_txt
                st.rerun()

    # æ¸…ç©ºæŒ‰éˆ•
    if st.button("ğŸ—‘ï¸ ä¸€éµæ¸…ç©ºé¸æ“‡", use_container_width=True):
        st.session_state.selected_links.clear()
        st.session_state.generated_text = ""
        st.rerun()

# ä¸»æ¨™é¡Œ
st.title("Tommy Sir å¾Œæ´æœƒä¹‹æ–°èç›£å¯Ÿç³»çµ±")

# ç”Ÿæˆå…§å®¹é¡¯ç¤ºå€åŸŸ (æ¨¡æ“¬ Popup æ•ˆæœ)
if st.session_state.generated_text:
    st.markdown('<div class="generated-box">', unsafe_allow_html=True)
    col_head, col_close = st.columns([0.9, 0.1])
    with col_head:
        st.success("âœ… ç”Ÿæˆå®Œæˆï¼è«‹è¤‡è£½ä¸‹æ–¹å…§å®¹ï¼š")
    with col_close:
        if st.button("âŒ", key="close_btn"):
            st.session_state.generated_text = ""
            st.rerun()
            
    st.text_area("", value=st.session_state.generated_text, height=400, key="txt_area")
    st.markdown('</div>', unsafe_allow_html=True)

# æ–°èç¶²æ ¼ (4 æ¬„ä½ˆå±€ï¼Œæ°´å¹³å°é½Š)
grid_cols = st.columns(4)

for idx, conf in enumerate(source_configs):
    with grid_cols[idx % 4]: # å¾ªç’°æ”¾å…¥ 4 å€‹æ¬„ä½
        name = conf['name']
        items = news_data_map.get(name, [])
        
        # æ¨™é¡Œå€
        st.markdown(f"""
            <div class='news-source-header' style='border-left: 5px solid {conf['color']}; padding-left: 10px;'>
                {name}
                <span class='status-badge'>{len(items)} å‰‡</span>
            </div>
        """, unsafe_allow_html=True)
        
        if not items:
            st.caption("æš«ç„¡è³‡æ–™")
        else:
            for item in items:
                link = item['link']
                is_new = is_new_news(item['time'])
                is_selected = link in st.session_state.selected_links
                
                c1, c2 = st.columns([0.15, 0.85])
                with c1:
                    def update_state(k=link):
                        if k in st.session_state.selected_links:
                            st.session_state.selected_links.remove(k)
                        else:
                            st.session_state.selected_links.add(k)
                    
                    st.checkbox("", key=f"chk_{link}", value=is_selected, on_change=update_state)
                
                with c2:
                    new_tag = '<span class="new-badge">NEW!</span>' if is_new else ''
                    text_style = 'class="read-text"' if is_selected else ""
                    
                    st.markdown(f"""
                        {new_tag}
                        <a href="{link}" target="_blank" {text_style}>
                            <b>{item['title']}</b>
                        </a><br>
                        <span style="font-size:0.8em; color:#888;">{item['time']}</span>
                    """, unsafe_allow_html=True)
