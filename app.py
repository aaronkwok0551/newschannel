# app.py
# -*- coding: utf-8 -*-

import datetime
import html
import re
import sys
from dataclasses import dataclass
from typing import List, Optional, Tuple, Dict

import feedparser
import pytz
import requests
import streamlit as st
from bs4 import BeautifulSoup
from streamlit_autorefresh import st_autorefresh


# =====================
# Runtime / Encoding
# =====================
try:
    sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass

HK_TZ = pytz.timezone("Asia/Hong_Kong")


# =====================
# Streamlit Page Config
# =====================
st.set_page_config(page_title="é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ", layout="wide", page_icon="ğŸ—ï¸")


# =====================
# CSS (å›ºå®šé«˜åº¦ + æ°´å¹³å°é½Š + ä¸é‹¸é½’)
# =====================
st.markdown(
    """
<style>
body { font-family: "Microsoft JhengHei","PingFang TC",sans-serif; }

.header-wrap { margin-bottom: 10px; }
.caption { color:#6b7280; font-size: 0.9rem; }

.grid-row { margin-top: 6px; }

.section-title{
  font-size:1.05rem;font-weight:800;margin:4px 0 10px 0;color:#111827;
}

.card{
  background:#ffffff;border:1px solid #e5e7eb;border-radius:14px;
  padding:12px;
  height:540px;
  display:flex;flex-direction:column;
}

.card-head{
  display:flex;align-items:center;justify-content:space-between;
  margin-bottom:8px;
}

.card-name{
  font-size:1.0rem;font-weight:800;color:#111827;
}

.badge{
  display:inline-block;
  padding:2px 8px;border-radius:999px;
  font-size:0.75rem;font-weight:700;
  border:1px solid #e5e7eb;background:#f9fafb;color:#374151;
}

.badge-warn{
  background:#fff7ed;border-color:#fed7aa;color:#9a3412;
}

.hint{
  font-size:0.78rem;color:#6b7280;margin:0 0 6px 0;
}

.items{ overflow-y:auto; padding-right:6px; flex:1; }

.item{
  background:#fff;border-left:4px solid #3b82f6;border-radius:10px;
  padding:8px 10px;margin:8px 0;
}

.item a{
  text-decoration:none;color:#111827;font-weight:650;line-height:1.35;
  display:block;
}
.item a:hover{ color:#ef4444; }

.item-meta{
  font-size:0.78rem;color:#6b7280;font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono","Courier New", monospace;
  margin-top:2px;
}

.empty{ color:#9ca3af;text-align:center;margin-top:18px; }
hr { border:none;border-top:1px solid #e5e7eb;margin:14px 0; }
</style>
""",
    unsafe_allow_html=True,
)


# =====================
# Model
# =====================
@dataclass
class Article:
    title: str
    link: str
    time_str: str
    color: str


# =====================
# Helpers
# =====================
def now_hk() -> datetime.datetime:
    return datetime.datetime.now(HK_TZ)

def today_hk() -> datetime.date:
    return now_hk().date()

def clean_text(raw: str) -> str:
    raw = html.unescape(raw or "")
    soup = BeautifulSoup(raw, "html.parser")
    text = soup.get_text(" ", strip=True)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def parse_feed_entry_dt(entry) -> Optional[datetime.datetime]:
    """
    RSS entries:
    - Prefer published_parsed / updated_parsed (struct_time)
    - Else try common string fields
    """
    stime = None
    if getattr(entry, "published_parsed", None):
        stime = entry.published_parsed
    elif getattr(entry, "updated_parsed", None):
        stime = entry.updated_parsed

    if stime:
        dt_utc = datetime.datetime(*stime[:6], tzinfo=pytz.utc)
        return dt_utc.astimezone(HK_TZ)

    # fallback: try strings (best-effort)
    for k in ("published", "updated", "pubDate"):
        v = getattr(entry, k, None)
        if v:
            try:
                # very small parser: let feedparser do main work; if string appears, skip strict parse
                # Use datetime.fromisoformat only if looks like ISO; else ignore to avoid false positives.
                s = str(v)
                if "T" in s and ("+" in s or "Z" in s):
                    s = s.replace("Z", "+00:00")
                    dt = datetime.datetime.fromisoformat(s)
                    if dt.tzinfo is None:
                        dt = HK_TZ.localize(dt)
                    return dt.astimezone(HK_TZ)
            except Exception:
                pass
    return None


# =====================
# Render (ä¸€æ¬¡æ€§è¼¸å‡ºï¼Œé¿å… HTML è¢«ç•¶æ–‡å­—)
# =====================
def build_card_html(title: str, articles: List[Article], warn: Optional[str] = None) -> str:
    badge_html = ""
    hint_html = ""

    if warn:
        badge_html = '<span class="badge badge-warn">æ³¨æ„</span>'
        hint_html = f'<div class="hint">âš ï¸ {html.escape(warn)}</div>'
    else:
        badge_html = '<span class="badge">ä»Šæ—¥</span>'

    if not articles:
        items_html = "<div class='empty'>ä»Šæ—¥æš«ç„¡æ–°è</div>"
    else:
        parts = []
        for a in articles:
            parts.append(
                f"""
                <div class="item" style="border-left-color:{a.color};">
                  <a href="{html.escape(a.link)}" target="_blank" rel="noopener noreferrer">{html.escape(a.title)}</a>
                  <div class="item-meta">ğŸ• {html.escape(a.time_str)}</div>
                </div>
                """
            )
        items_html = "".join(parts)

    return f"""
    <div class="card">
      <div class="card-head">
        <div class="card-name">{html.escape(title)}</div>
        {badge_html}
      </div>
      {hint_html}
      <div class="items">
        {items_html}
      </div>
    </div>
    """


# =====================
# Fetchers
# =====================
def _safe_get_json(url: str, params: dict, timeout: int = 12):
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; HKNewsAggregator/1.0)",
        "Accept": "application/json, text/plain, */*",
        "Referer": "https://news.now.com/",
        "Origin": "https://news.now.com",
    }
    r = requests.get(url, params=params, headers=headers, timeout=timeout)
    r.raise_for_status()
    return r.json()

def _now_ms_to_hk(ms: int) -> Optional[datetime.datetime]:
    try:
        dt_utc = datetime.datetime.fromtimestamp(int(ms) / 1000, tz=pytz.utc)
        return dt_utc.astimezone(HK_TZ)
    except Exception:
        return None


@st.cache_data(ttl=60)
def fetch_rss_today_or_top10(url: str, color: str, limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    ä½ çš„è¦å‰‡ï¼š
    - å„ªå…ˆåš´æ ¼é¡¯ç¤ºã€Œä»Šæ—¥ã€
    - å¦‚æœä¾†æºç„¡æ³•åˆ¤æ–·æ—¥æœŸ/æ™‚é–“ï¼šè®€å–é ­ 10 æ¢ï¼Œä¸¦æŠŠæ™‚é–“æ¬„æ”¹æˆã€Œä»Šæ—¥ YYYY-MM-DDã€
    """
    feed = feedparser.parse(url)
    entries = feed.entries or []
    if not entries:
        return [], "ä¾†æºç„¡æ¢ç›®æˆ–æš«æ™‚ç„¡æ³•è®€å–"

    today = today_hk()
    out_today: List[Article] = []
    out_top: List[Article] = []
    undated_count = 0

    for e in entries:
        title = clean_text(getattr(e, "title", ""))
        link = getattr(e, "link", "")
        if not title or not link:
            continue

        dt = parse_feed_entry_dt(e)
        if dt is None:
            undated_count += 1
            out_top.append(Article(title=title, link=link, time_str=f"ä»Šæ—¥ {today.strftime('%Y-%m-%d')}", color=color))
        else:
            if dt.date() == today:
                out_today.append(Article(title=title, link=link, time_str=dt.strftime("%H:%M"), color=color))

        # æ”¶é›† top10 å‚™ç”¨
        if len(out_top) < limit and dt is not None:
            out_top.append(Article(title=title, link=link, time_str=dt.strftime("%H:%M"), color=color))

        if len(out_today) >= limit and len(out_top) >= limit:
            break

    if out_today:
        return out_today[:limit], None

    # ä»Šæ—¥ç‚º 0ï¼šæŒ‰ä½ çš„è¦æ±‚ï¼Œå–é ­ 10 æ¢ä¸¦ã€Œç·¨ä¿®æ²’æœ‰æ™‚é–“ã€
    warn = "æœªèƒ½ç¯©å‡ºã€ä»Šæ—¥ã€æ–°èï¼ˆæˆ–æ™‚é–“æ¬„ä½ç¼ºå¤±ï¼‰ï¼Œå·²é¡¯ç¤ºæœ€æ–° 10 æ¢ä¸¦ä»¥ã€ä»Šæ—¥ã€æ¨™ç¤º"
    if undated_count == 0:
        warn = "ä¾†æºå›å‚³æ™‚é–“å¯èƒ½éé¦™æ¸¯æ™‚é–“æˆ–æ ¼å¼æ”¹å‹•ï¼Œå·²é¡¯ç¤ºæœ€æ–° 10 æ¢"
    return out_top[:limit], warn


# ---- Nowï¼šä¸ç”¨ RSSHubï¼Œç›´æ¥ XHR JSON ----
NOW_API = "https://newsapi1.now.com/pccw-news-api/api/getNewsListv2"

@st.cache_data(ttl=60)
def fetch_now_local_today(limit: int = 10) -> Tuple[List[Article], Optional[str]]:
    """
    Now æœ¬åœ°ï¼šcategory=119
    - æ”¯æ´ root listï¼ˆä½ è²¼çš„æ ¼å¼ï¼‰
    - publishDate = æ¯«ç§’ timestamp
    - webUrl å¯èƒ½ç‚º nullï¼šç”¨ newsId çµ„ player link
    - åš´æ ¼ä»Šæ—¥ï¼›è‹¥ä»Šæ—¥ç¯©ä¸åˆ°ä½†æœ‰è³‡æ–™ï¼šfallback æœ€æ–°10
    """
    color = "#3B82F6"
    today = today_hk()
    out_today: List[Article] = []
    out_latest: List[Article] = []

    try:
        data = _safe_get_json(NOW_API, {"category": 119, "pageNo": 1}, timeout=12)

        # root å¯èƒ½ä¿‚ list æˆ– dict
        if isinstance(data, list):
            candidates = data
        elif isinstance(data, dict):
            # å…¼å®¹å¦ä¸€ç¨®åŒ…è£
            candidates = None
            for k in ("data", "list", "news", "items", "result"):
                v = data.get(k)
                if isinstance(v, list):
                    candidates = v
                    break
            if candidates is None:
                # å†æƒä¸€å±¤
                for v in data.values():
                    if isinstance(v, dict):
                        for kk in ("data", "list", "news", "items", "result"):
                            vv = v.get(kk)
                            if isinstance(vv, list):
                                candidates = vv
                                break
                    if candidates is not None:
                        break
            if candidates is None:
                candidates = []
        else:
            candidates = []

        if not candidates:
            return [], "Now API ç„¡å¯ç”¨è³‡æ–™ï¼ˆå¯èƒ½æ”¹ç‰ˆæˆ–è¢«å°é–ï¼‰"

        for it in candidates:
            if not isinstance(it, dict):
                continue

            title = clean_text(str(it.get("title") or it.get("newsTitle") or ""))
            if not title:
                continue

            dt = _now_ms_to_hk(it.get("publishDate")) if it.get("publishDate") is not None else None
            time_str = dt.strftime("%H:%M") if dt else f"ä»Šæ—¥ {today.strftime('%Y-%m-%d')}"

            news_id = it.get("newsId")
            link = it.get("webUrl") or it.get("shareUrl") or it.get("url") or ""
            if not link:
                if news_id:
                    link = f"https://news.now.com/home/local/player?newsId={news_id}"
                else:
                    continue

            art = Article(title=title, link=link, time_str=time_str, color=color)
            out_latest.append(art)
            if dt and dt.date() == today:
                out_today.append(art)

            if len(out_latest) >= limit:
                break

        if out_today:
            return out_today[:limit], None

        if out_latest:
            return out_latest[:limit], "æœªèƒ½ä»¥æ™‚é–“æ¬„ä½ç¯©å‡ºã€ä»Šæ—¥ã€ï¼Œå·²é¡¯ç¤ºæœ€æ–° 10 æ¢"
        return [], "Now API æœ‰å›å‚³ä½†æœªèƒ½è§£æåˆ°æœ‰æ•ˆæ–°è"

    except Exception as e:
        return [], f"Now API è®€å–å¤±æ•—ï¼š{type(e).__name__}: {e}"


# =====================
# Sources (æŒ‰ä½ æŒ‡å®š)
# =====================
RSSHUB_BASE = "https://rsshub-production-9dfc.up.railway.app"

# å®˜æ–¹ RSS
GOV_ZH = "https://www.info.gov.hk/gia/rss/general_zh.xml"
GOV_EN = "https://www.info.gov.hk/gia/rss/general_en.xml"
RTHK = "https://rthk.hk/rthk/news/rss/c_expressnews_clocal.xml"
MINGPAO = "https://news.mingpao.com/rss/ins/s00001.xml"
HKET = "https://www.hket.com/rss/hongkong"

# RSSHub routesï¼ˆä½ æä¾›ï¼‰
RSSHUB_SOURCES: List[Tuple[str, str, str]] = [
    ("HK01ï¼ˆæœ€æ–°ï¼‰", f"{RSSHUB_BASE}/hk01/latest", "#1F4E79"),
    ("on.cc æ±ç¶²ï¼ˆå³æ™‚ï¼‰", f"{RSSHUB_BASE}/oncc/zh-hant/news", "#111827"),
    ("TVB æ–°èï¼ˆæœ¬åœ°ï¼‰", f"{RSSHUB_BASE}/tvb/news/tc", "#10B981"),
    ("ä¿¡å ±å³æ™‚ï¼ˆHKEJï¼‰", f"{RSSHUB_BASE}/hkej/index", "#7C3AED"),
    ("æ˜Ÿå³¶å³æ™‚", f"{RSSHUB_BASE}/stheadline/std/realtime", "#DC2626"),
    ("i-CABLE æœ‰ç·šï¼ˆå³æ™‚ï¼‰", f"{RSSHUB_BASE}/icable/all", "#EF4444"),
]

# ä½ æåˆ°å•†æ¥­é›»å°ä¸æº–ï¼šå…ˆä¸ç¡¬åŠ ï¼Œä¿ç•™ä½ æ—¥å¾Œå¡«å…¥
# COMMERCIAL_RADIO = ( "å•†æ¥­é›»å°", f"{RSSHUB_BASE}/xxx/xxx", "#2563EB" )


# =====================
# UI
# =====================
st.markdown('<div class="header-wrap">', unsafe_allow_html=True)
st.markdown("## ğŸ—ï¸ é¦™æ¸¯æ–°èèšåˆä¸­å¿ƒ")
st.markdown(f'<div class="caption">æœ€å¾Œæ›´æ–°ï¼ˆé¦™æ¸¯æ™‚é–“ï¼‰ï¼š{now_hk().strftime("%Y-%m-%d %H:%M:%S")}</div>', unsafe_allow_html=True)
st.markdown("</div>", unsafe_allow_html=True)

auto = st.toggle("æ¯åˆ†é˜è‡ªå‹•æ›´æ–°", value=True)
if auto:
    st_autorefresh(interval=60_000, key="auto_refresh_60s")

st.markdown("<hr/>", unsafe_allow_html=True)

# ===== ç¬¬ä¸€è¡Œï¼šæ”¿åºœä¸­ / æ”¿åºœè‹± / RTHK / Nowæœ¬åœ° =====
row1 = st.columns(4, gap="medium")

with row1[0]:
    arts, warn = fetch_rss_today_or_top10(GOV_ZH, "#E74C3C", limit=10)
    st.markdown(build_card_html("æ”¿åºœæ–°èï¼ˆä¸­æ–‡ï¼‰", arts, warn), unsafe_allow_html=True)

with row1[1]:
    arts, warn = fetch_rss_today_or_top10(GOV_EN, "#C0392B", limit=10)
    st.markdown(build_card_html("æ”¿åºœæ–°èï¼ˆè‹±æ–‡ï¼‰", arts, warn), unsafe_allow_html=True)

with row1[2]:
    arts, warn = fetch_rss_today_or_top10(RTHK, "#FF9800", limit=10)
    st.markdown(build_card_html("RTHKï¼ˆæœ¬åœ°ï¼‰", arts, warn), unsafe_allow_html=True)

with row1[3]:
    arts, warn = fetch_now_local_today(limit=10)
    st.markdown(build_card_html("Now æ–°èï¼ˆæœ¬åœ°ï¼‰", arts, warn), unsafe_allow_html=True)

st.markdown("<hr/>", unsafe_allow_html=True)

# ===== ç¬¬äºŒéƒ¨åˆ†ï¼šå…¶é¤˜åª’é«”ï¼ˆæ¯è¡Œ 5 å€‹ï¼Œæ°´å¹³å°é½Šï¼‰=====
st.markdown('<div class="section-title">å…¶ä»–æ–°èåª’é«”ï¼ˆæ¯å€‹ä¾†æº 10 æ¢ã€å„ªå…ˆä»Šæ—¥ï¼‰</div>', unsafe_allow_html=True)

other_sources: List[Tuple[str, str, str]] = []
# ä½ æåˆ°çš„ã€Œç¶“æ¿Ÿæ—¥å ±ã€ã€ã€Œæ˜å ±ã€å®˜æ–¹ RSS
other_sources.append(("ç¶“æ¿Ÿæ—¥å ± HKETï¼ˆæ¸¯èï¼‰", HKET, "#6B7280"))
other_sources.append(("æ˜å ±ï¼ˆå³æ™‚ï¼‰", MINGPAO, "#374151"))
# RSSHub åª’é«”
other_sources.extend(RSSHUB_SOURCES)

# æ¯è¡Œ 5 å€‹
per_row = 5
for i in range(0, len(other_sources), per_row):
    cols = st.columns(per_row, gap="medium")
    chunk = other_sources[i:i + per_row]
    for j in range(per_row):
        with cols[j]:
            if j >= len(chunk):
                # ç©ºä½è£œé½Šï¼Œä¿æŒå°é½Š
                st.markdown('<div class="card"><div class="empty"> </div></div>', unsafe_allow_html=True)
                continue
            name, url, color = chunk[j]
            arts, warn = fetch_rss_today_or_top10(url, color, limit=10)
            st.markdown(build_card_html(name, arts, warn), unsafe_allow_html=True)

st.caption(
    "å‚™è¨»ï¼šè‹¥æŸä¾†æºé•·æœŸé¡¯ç¤ºã€ä¾†æºç„¡æ¢ç›®æˆ–æš«æ™‚ç„¡æ³•è®€å–ã€ï¼Œå¤šåŠæ˜¯ RSSHub è·¯å¾‘æˆ–ä¸Šæ¸¸ç¶²ç«™æ”¹ç‰ˆï¼›åªéœ€æ›´æ–°è©²ä¾†æº URLã€‚"
)
